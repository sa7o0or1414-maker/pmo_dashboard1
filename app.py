import os
import re
from datetime import date

import pandas as pd
import streamlit as st
import plotly.express as px

from utils.layout import render_header
from utils.settings import load_settings

# --------------------------------------------------
# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© (Dashboard)
# --------------------------------------------------
st.set_page_config(page_title="Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©", page_icon="ğŸ ", layout="wide")

# âœ… Ù†Ø®ÙÙŠ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ØµÙØ­Ø§Øª Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ© (Ø§Ù„Ù„ÙŠ ÙŠØ·Ù„Ø¹ ÙÙŠÙ‡Ø§ App)
st.markdown(
    """
    <style>
      div[data-testid="stSidebarNav"] { display: none !important; }
    </style>
    """,
    unsafe_allow_html=True,
)

# --------------------------------------------------
# Ø§ÙƒØªØ´Ø§Ù ØµÙØ­Ø§Øª Ù…Ø¬Ù„Ø¯ pages ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§ (Ø¨Ø¯ÙˆÙ† Ù…Ø§ Ù†Ø¹Ø±Ù Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù)
# --------------------------------------------------
def list_pages():
    pages_dir = "pages"
    if not os.path.isdir(pages_dir):
        return []
    files = []
    for f in os.listdir(pages_dir):
        if f.endswith(".py") and not f.startswith("_"):
            files.append(f)
    return sorted(files)

def find_page_by_keywords(keywords):
    """
    ÙŠØ¨Ø­Ø« Ø¯Ø§Ø®Ù„ Ø£Ø³Ù…Ø§Ø¡ Ù…Ù„ÙØ§Øª pages Ø¹Ù† Ø£ÙŠ Ù…Ù„Ù ÙŠØ­ØªÙˆÙŠ ÙƒÙ„ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©.
    """
    pages = list_pages()
    for f in pages:
        name = f.lower()
        ok = True
        for kw in keywords:
            if kw.lower() not in name:
                ok = False
                break
        if ok:
            return f"pages/{f}"
    return None

# Ù†Ø­Ø§ÙˆÙ„ Ù†Ù„Ù‚Ø· Ø§Ù„ØµÙØ­Ø§Øª (Ø±ÙØ¹/Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª/ØªØ³Ø¬ÙŠÙ„) Ù…Ù‡Ù…Ø§ ÙƒØ§Ù† Ø±Ù‚Ù…Ù‡Ø§ Ø£Ùˆ Ø§Ù„Ø¥ÙŠÙ…ÙˆØ¬ÙŠ
upload_page = find_page_by_keywords(["Ø±ÙØ¹"]) or find_page_by_keywords(["upload"])
settings_page = find_page_by_keywords(["Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª"]) or find_page_by_keywords(["Ø§Ø¹Ø¯Ø§Ø¯Ø§Øª"]) or find_page_by_keywords(["settings"])
login_page = find_page_by_keywords(["ØªØ³Ø¬ÙŠÙ„"]) or find_page_by_keywords(["login"])

# --------------------------------------------------
# Ø³Ø§ÙŠØ¯Ø¨Ø§Ø± Ù…Ø®ØµØµ Ø¨Ø§Ù„ØªØ±ØªÙŠØ¨ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨
# --------------------------------------------------
st.sidebar.markdown(
    """
    <div style="text-align:center; font-size:20px; font-weight:800; margin-top:8px;">
        ğŸ  Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
    </div>
    <div style="text-align:center; font-size:14px; opacity:0.9; margin-bottom:14px;">
        Ù„ÙˆØ­Ø© Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª
    </div>
    <hr style="margin: 10px 0 14px 0; opacity:0.3;">
    """,
    unsafe_allow_html=True,
)

# Ø£Ø²Ø±Ø§Ø± ØªÙ†Ù‚Ù„Ùƒ Ù„Ù„ØµÙØ­Ø§Øª (ØªØ±ØªÙŠØ¨Ùƒ: Ø±ÙØ¹ -> Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª -> ØªØ³Ø¬ÙŠÙ„)
if st.sidebar.button("ğŸ“¤ Ø±ÙØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª", use_container_width=True):
    if upload_page:
        st.switch_page(upload_page)
    else:
        st.sidebar.error("Ù„Ù… Ø£Ø¬Ø¯ ØµÙØ­Ø© (Ø±ÙØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª) Ø¯Ø§Ø®Ù„ Ù…Ø¬Ù„Ø¯ pages.")

if st.sidebar.button("ğŸ¨ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª", use_container_width=True):
    if settings_page:
        st.switch_page(settings_page)
    else:
        st.sidebar.error("Ù„Ù… Ø£Ø¬Ø¯ ØµÙØ­Ø© (Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª) Ø¯Ø§Ø®Ù„ Ù…Ø¬Ù„Ø¯ pages.")

if st.sidebar.button("ğŸ” ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„", use_container_width=True):
    if login_page:
        st.switch_page(login_page)
    else:
        st.sidebar.error("Ù„Ù… Ø£Ø¬Ø¯ ØµÙØ­Ø© (ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„) Ø¯Ø§Ø®Ù„ Ù…Ø¬Ù„Ø¯ pages.")

st.sidebar.markdown("<hr style='margin:14px 0; opacity:0.3;'>", unsafe_allow_html=True)

# (Ø§Ø®ØªÙŠØ§Ø±ÙŠ) Ù„Ùˆ Ø­Ø¨ÙŠØªÙŠ ØªØ´ÙˆÙÙŠ Ø£Ø³Ù…Ø§Ø¡ Ù…Ù„ÙØ§Øª pages Ø§Ù„Ù…ØªÙˆÙØ±Ø© Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ¬Ø±Ø¨Ø©:
with st.sidebar.expander("ğŸ§© ØµÙØ­Ø§Øª Ù…ÙˆØ¬ÙˆØ¯Ø© (Ù„Ù„ØªØ£ÙƒØ¯)", expanded=False):
    pages_now = list_pages()
    if pages_now:
        for p in pages_now:
            st.write("â€¢", p)
    else:
        st.info("Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù…Ø¬Ù„Ø¯ pages Ø£Ùˆ Ù„Ø§ ØªÙˆØ¬Ø¯ ØµÙØ­Ø§Øª.")

# --------------------------------------------------
# Ù‡ÙŠØ¯Ø± Ø£Ø¹Ù„Ù‰ Ø§Ù„ØµÙØ­Ø© (Ù„ÙˆØºÙˆ + Ø¹Ù†ÙˆØ§Ù† + Ù„ØºØ© Ø­Ø³Ø¨ Ù†Ø¸Ø§Ù…Ùƒ)
# --------------------------------------------------
render_header(title_key_base="dashboard_title", page_title_fallback="ğŸ“Š Ù„ÙˆØ­Ø© Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª")

# --------------------------------------------------
# Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
# --------------------------------------------------
settings = load_settings()
theme = settings.get("theme", {})
palette = theme.get("palette", ["#3B82F6", "#22C55E", "#F59E0B", "#EF4444", "#A855F7"])

data_cfg = settings.get("data", {})
lat_col = data_cfg.get("lat_col", "lat")
lon_col = data_cfg.get("lon_col", "lon")
map_link_col = data_cfg.get("map_link_col", "Ø±Ø§Ø¨Ø· Ø§Ù„Ù…ÙˆÙ‚Ø¹")
show_map = bool(data_cfg.get("show_map", True))

# --------------------------------------------------
# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
# --------------------------------------------------
path = os.path.join("data", "latest.xlsx")
if not os.path.exists(path):
    st.warning("Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù…Ù„Ù Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø¹Ø¯. Ø§Ø°Ù‡Ø¨ÙŠ Ù„ØµÙØ­Ø© (Ø±ÙØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª) ÙˆØ§Ø±ÙØ¹Ù Ù…Ù„Ù Excel.")
    st.stop()

df = pd.read_excel(path, sheet_name=0)
df.columns = [str(c).strip() for c in df.columns]

# --------------------------------------------------
# Helpers
# --------------------------------------------------
def safe_unique(frame: pd.DataFrame, col: str):
    if col not in frame.columns:
        return []
    return sorted([x for x in frame[col].dropna().unique().tolist()])

def parse_latlon_from_link(link: str):
    if not isinstance(link, str) or not link:
        return None, None
    m = re.search(r"@(-?\d+\.\d+),(-?\d+\.\d+)", link)
    if m:
        return float(m.group(1)), float(m.group(2))
    m = re.search(r"[?&]q=(-?\d+\.\d+),(-?\d+\.\d+)", link)
    if m:
        return float(m.group(1)), float(m.group(2))
    return None, None

def ensure_latlon(frame: pd.DataFrame) -> pd.DataFrame:
    out = frame.copy()
    if lat_col in out.columns and lon_col in out.columns:
        out[lat_col] = pd.to_numeric(out[lat_col], errors="coerce")
        out[lon_col] = pd.to_numeric(out[lon_col], errors="coerce")
        return out

    if map_link_col in out.columns:
        lats, lons = [], []
        for x in out[map_link_col].fillna("").astype(str).tolist():
            la, lo = parse_latlon_from_link(x)
            lats.append(la)
            lons.append(lo)
        out[lat_col] = pd.to_numeric(pd.Series(lats), errors="coerce")
        out[lon_col] = pd.to_numeric(pd.Series(lons), errors="coerce")
        return out

    out[lat_col] = pd.NA
    out[lon_col] = pd.NA
    return out

def _fmt_days(x):
    try:
        if pd.isna(x):
            return "â€”"
        return f"{int(round(float(x))):,} ÙŠÙˆÙ…"
    except Exception:
        return "â€”"

def _fmt_pct(x):
    try:
        if pd.isna(x):
            return "â€”"
        return f"{float(x):.1f}%"
    except Exception:
        return "â€”"

def show_dropdown(table_df: pd.DataFrame, title: str):
    if len(table_df) == 0:
        st.info("Ù„Ø§ ØªÙˆØ¬Ø¯ Ù†ØªØ§Ø¦Ø¬.")
        return

    name_col = "Ø¥Ø³Ù… Ø§Ù„Ù…Ø´Ù€Ù€Ù€Ø±ÙˆØ¹" if "Ø¥Ø³Ù… Ø§Ù„Ù…Ø´Ù€Ù€Ù€Ø±ÙˆØ¹" in table_df.columns else None
    with st.expander(title, expanded=True):
        if name_col:
            st.markdown("**Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…Ø´Ø§Ø±ÙŠØ¹:**")
            for n in table_df[name_col].dropna().astype(str).unique().tolist():
                st.write("â€¢", n)

        cols_show = [c for c in [
            "Ø±Ù‚Ù… Ø§Ù„Ø¹Ù‚Ø¯",
            "Ø¥Ø³Ù… Ø§Ù„Ù…Ø´Ù€Ù€Ù€Ø±ÙˆØ¹",
            "Ø§Ù„Ø¨Ù„Ø¯ÙŠØ©",
            "Ø§Ù„Ø¬Ù‡Ø©",
            "Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ø´Ø±ÙˆØ¹",
            "Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²",
            "ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„Ù…Ø´Ø±ÙˆØ¹",
            "forecast_end",
            "variance_days",
            "reason",
        ] if c in table_df.columns]

        st.dataframe(table_df[cols_show], use_container_width=True)

# --------------------------------------------------
# ÙÙ„Ø§ØªØ± (ØªØ­Øª Ø§Ù„Ù‚Ø§Ø¦Ù…Ø©)
# --------------------------------------------------
st.sidebar.markdown("### ğŸ” ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù†ØªØ§Ø¦Ø¬")
status_opt = ["Ø§Ù„ÙƒÙ„"] + safe_unique(df, "Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ø´Ø±ÙˆØ¹")
mun_opt = ["Ø§Ù„ÙƒÙ„"] + safe_unique(df, "Ø§Ù„Ø¨Ù„Ø¯ÙŠØ©")
entity_opt = ["Ø§Ù„ÙƒÙ„"] + safe_unique(df, "Ø§Ù„Ø¬Ù‡Ø©")

status = st.sidebar.selectbox("Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ø´Ø±ÙˆØ¹", status_opt)
mun = st.sidebar.selectbox("Ø§Ù„Ø¨Ù„Ø¯ÙŠØ©", mun_opt)
entity = st.sidebar.selectbox("Ø§Ù„Ø¬Ù‡Ø©", entity_opt)

filtered = df.copy()
if status != "Ø§Ù„ÙƒÙ„" and "Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ø´Ø±ÙˆØ¹" in filtered.columns:
    filtered = filtered[filtered["Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ø´Ø±ÙˆØ¹"] == status]
if mun != "Ø§Ù„ÙƒÙ„" and "Ø§Ù„Ø¨Ù„Ø¯ÙŠØ©" in filtered.columns:
    filtered = filtered[filtered["Ø§Ù„Ø¨Ù„Ø¯ÙŠØ©"] == mun]
if entity != "Ø§Ù„ÙƒÙ„" and "Ø§Ù„Ø¬Ù‡Ø©" in filtered.columns:
    filtered = filtered[filtered["Ø§Ù„Ø¬Ù‡Ø©"] == entity]

# --------------------------------------------------
# KPIs
# --------------------------------------------------
k1, k2, k3, k4 = st.columns(4)
k1.metric("Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø´Ø§Ø±ÙŠØ¹", f"{len(filtered):,}")
k2.metric("Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ù‚ÙŠÙ…Ø© Ø§Ù„Ø¹Ù‚ÙˆØ¯", f"{filtered['Ù‚ÙŠÙ…Ø© Ø§Ù„Ø¹Ù‚Ø¯'].fillna(0).sum():,.0f}" if "Ù‚ÙŠÙ…Ø© Ø§Ù„Ø¹Ù‚Ø¯" in filtered.columns else "â€”")
k3.metric("Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…Ø³ØªØ®Ù„ØµØ§Øª", f"{filtered['Ù‚ÙŠÙ…Ø© Ø§Ù„Ù…Ø³ØªØ®Ù„ØµØ§Øª Ø§Ù„Ù…Ø¹ØªÙ…Ø¯Ù‡'].fillna(0).sum():,.0f}" if "Ù‚ÙŠÙ…Ø© Ø§Ù„Ù…Ø³ØªØ®Ù„ØµØ§Øª Ø§Ù„Ù…Ø¹ØªÙ…Ø¯Ù‡" in filtered.columns else "â€”")
k4.metric("Ù…ØªÙˆØ³Ø· Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²", f"{pd.to_numeric(filtered['Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²'], errors='coerce').fillna(0).mean():.1f}%" if "Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²" in filtered.columns else "â€”")

st.divider()

# --------------------------------------------------
# Alerts + Forecast + Reasons
# --------------------------------------------------
alerts = filtered.copy()
today = pd.Timestamp(date.today())

for col in ["ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„Ù…Ø´Ø±ÙˆØ¹", "ØªØ§Ø±ÙŠØ® ØªØ³Ù„ÙŠÙ… Ø§Ù„Ù…ÙˆÙ‚Ø¹"]:
    if col in alerts.columns:
        alerts[col] = pd.to_datetime(alerts[col], errors="coerce")

if "Ø§Ù„Ù…Ø¯Ø© Ø§Ù„Ù…Ù†Ù‚Ø¶ÙŠØ© Ø¨Ø§Ù„Ø§ÙŠØ§Ù…" in alerts.columns:
    alerts["Ø§Ù„Ù…Ø¯Ø© Ø§Ù„Ù…Ù†Ù‚Ø¶ÙŠØ© Ø¨Ø§Ù„Ø§ÙŠØ§Ù…"] = pd.to_numeric(alerts["Ø§Ù„Ù…Ø¯Ø© Ø§Ù„Ù…Ù†Ù‚Ø¶ÙŠØ© Ø¨Ø§Ù„Ø§ÙŠØ§Ù…"], errors="coerce")
if "Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²" in alerts.columns:
    alerts["Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²"] = pd.to_numeric(alerts["Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²"], errors="coerce")

alerts["predicted_total_days"] = pd.Series([None] * len(alerts), dtype="float64")
alerts["forecast_end"] = pd.NaT

MAX_PREDICT_DAYS = 20000
MIN_PROGRESS = 0.5
MAX_PROGRESS = 100

can_forecast = ("Ø§Ù„Ù…Ø¯Ø© Ø§Ù„Ù…Ù†Ù‚Ø¶ÙŠØ© Ø¨Ø§Ù„Ø§ÙŠØ§Ù…" in alerts.columns) and ("Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²" in alerts.columns) and ("ØªØ§Ø±ÙŠØ® ØªØ³Ù„ÙŠÙ… Ø§Ù„Ù…ÙˆÙ‚Ø¹" in alerts.columns)
if can_forecast:
    valid = (
        alerts["Ø§Ù„Ù…Ø¯Ø© Ø§Ù„Ù…Ù†Ù‚Ø¶ÙŠØ© Ø¨Ø§Ù„Ø§ÙŠØ§Ù…"].notna()
        & alerts["ØªØ§Ø±ÙŠØ® ØªØ³Ù„ÙŠÙ… Ø§Ù„Ù…ÙˆÙ‚Ø¹"].notna()
        & alerts["Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²"].notna()
        & (alerts["Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²"] >= MIN_PROGRESS)
        & (alerts["Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²"] <= MAX_PROGRESS)
        & (alerts["Ø§Ù„Ù…Ø¯Ø© Ø§Ù„Ù…Ù†Ù‚Ø¶ÙŠØ© Ø¨Ø§Ù„Ø§ÙŠØ§Ù…"] >= 0)
    )

    pred = alerts.loc[valid, "Ø§Ù„Ù…Ø¯Ø© Ø§Ù„Ù…Ù†Ù‚Ø¶ÙŠØ© Ø¨Ø§Ù„Ø§ÙŠØ§Ù…"] / (alerts.loc[valid, "Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²"] / 100.0)
    pred = pred.where((pred >= 0) & (pred <= MAX_PREDICT_DAYS), other=pd.NA)
    alerts.loc[valid, "predicted_total_days"] = pred

    valid2 = alerts["predicted_total_days"].notna()
    alerts.loc[valid2, "forecast_end"] = (
        alerts.loc[valid2, "ØªØ§Ø±ÙŠØ® ØªØ³Ù„ÙŠÙ… Ø§Ù„Ù…ÙˆÙ‚Ø¹"] + pd.to_timedelta(alerts.loc[valid2, "predicted_total_days"], unit="D", errors="coerce")
    )

alerts["is_overdue"] = False
if "ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„Ù…Ø´Ø±ÙˆØ¹" in alerts.columns:
    prog = alerts["Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²"] if "Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²" in alerts.columns else pd.Series([0] * len(alerts))
    alerts["is_overdue"] = (
        alerts["ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„Ù…Ø´Ø±ÙˆØ¹"].notna()
        & (today > alerts["ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„Ù…Ø´Ø±ÙˆØ¹"])
        & (prog.fillna(0) < 100)
    )

alerts["is_forecast_late"] = False
if "ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„Ù…Ø´Ø±ÙˆØ¹" in alerts.columns:
    alerts["is_forecast_late"] = (
        alerts["forecast_end"].notna()
        & alerts["ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„Ù…Ø´Ø±ÙˆØ¹"].notna()
        & (alerts["forecast_end"] > alerts["ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„Ù…Ø´Ø±ÙˆØ¹"])
    )

alerts["variance_days"] = pd.NA
if "ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„Ù…Ø´Ø±ÙˆØ¹" in alerts.columns:
    alerts["variance_days"] = (alerts["forecast_end"] - alerts["ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„Ù…Ø´Ø±ÙˆØ¹"]).dt.days

def build_reason(row):
    if bool(row.get("is_overdue", False)):
        planned = row.get("ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„Ù…Ø´Ø±ÙˆØ¹", pd.NaT)
        if pd.isna(planned):
            return "Ù…ØªØ£Ø®Ø± ÙØ¹Ù„ÙŠÙ‹Ø§: ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ø§Ù„Ù…Ø®Ø·Ø· ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯."
        return f"Ù…ØªØ£Ø®Ø± ÙØ¹Ù„ÙŠÙ‹Ø§: ØªØ¬Ø§ÙˆØ² Ø§Ù„Ù…Ø®Ø·Ø· Ø¨Ù€ {(today - planned).days} ÙŠÙˆÙ…."

    if bool(row.get("is_forecast_late", False)):
        progress = row.get("Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²", pd.NA)
        elapsed = row.get("Ø§Ù„Ù…Ø¯Ø© Ø§Ù„Ù…Ù†Ù‚Ø¶ÙŠØ© Ø¨Ø§Ù„Ø§ÙŠØ§Ù…", pd.NA)
        predicted = row.get("predicted_total_days", pd.NA)
        forecast_end = row.get("forecast_end", pd.NaT)
        planned_end = row.get("ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„Ù…Ø´Ø±ÙˆØ¹", pd.NaT)
        variance = row.get("variance_days", pd.NA)

        missing = []
        if pd.isna(progress): missing.append("Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²")
        if pd.isna(elapsed): missing.append("Ø§Ù„Ù…Ø¯Ø© Ø§Ù„Ù…Ù†Ù‚Ø¶ÙŠØ©")
        if pd.isna(predicted): missing.append("Ø£ÙŠØ§Ù… Ù…ØªÙˆÙ‚Ø¹Ø© Ø¥Ø¬Ù…Ø§Ù„Ù‹Ø§")
        if pd.isna(forecast_end): missing.append("ØªØ§Ø±ÙŠØ® Ø§Ù„ØªÙ†Ø¨Ø¤")
        if pd.isna(planned_end): missing.append("ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ø§Ù„Ù…Ø®Ø·Ø·")
        if missing:
            return "Ù…ØªÙˆÙ‚Ø¹ ÙŠØªØ£Ø®Ø±: Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± ÙƒØ§ÙÙŠØ© (" + "ØŒ ".join(missing) + ")."

        return (
            f"Ø§Ù„ØªÙ†Ø¨Ø¤: Ù…Ø¯Ø© {_fmt_days(elapsed)} Ù…Ø¹ Ø¥Ù†Ø¬Ø§Ø² {_fmt_pct(progress)} "
            f"â‡’ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ù…ØªÙˆÙ‚Ø¹ {_fmt_days(predicted)} "
            f"â‡’ ØªØ§Ø±ÙŠØ® Ø§Ù„ØªÙ†Ø¨Ø¤ {pd.to_datetime(forecast_end).date()} "
            f"Ø£Ø¨Ø¹Ø¯ Ù…Ù† Ø§Ù„Ù…Ø®Ø·Ø· Ø¨Ù€ {int(variance)} ÙŠÙˆÙ…."
        )
    return ""

alerts["reason"] = alerts.apply(build_reason, axis=1)

# Toggle (Ø¶ØºØ·Ø© ØªØ¸Ù‡Ø±/Ø¶ØºØ·Ø© ØªØ®ØªÙÙŠ)
if "alerts_toggle" not in st.session_state:
    st.session_state.alerts_toggle = None  # None | overdue | forecast

overdue_count = int(alerts["is_overdue"].sum())
forecast_count = int(alerts["is_forecast_late"].sum())

col_over, col_fore = st.columns(2)

with col_over:
    if st.button(f"â›” Ù…ØªØ£Ø®Ø± ÙØ¹Ù„ÙŠÙ‹Ø§ â€¢ {overdue_count:,}", use_container_width=True):
        st.session_state.alerts_toggle = None if st.session_state.alerts_toggle == "overdue" else "overdue"
    if st.session_state.alerts_toggle == "overdue":
        show_dropdown(alerts[alerts["is_overdue"]].copy(), "ğŸ“Œ ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ù…ØªØ£Ø®Ø±Ø© ÙØ¹Ù„ÙŠÙ‹Ø§")

with col_fore:
    if st.button(f"âš ï¸ Ù…ØªÙˆÙ‚Ø¹ ÙŠØªØ£Ø®Ø± (Forecast) â€¢ {forecast_count:,}", use_container_width=True):
        st.session_state.alerts_toggle = None if st.session_state.alerts_toggle == "forecast" else "forecast"
    if st.session_state.alerts_toggle == "forecast":
        show_dropdown(alerts[alerts["is_forecast_late"]].copy(), "ğŸ“Œ ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹ ØªØ£Ø®Ø±Ù‡Ø§ + Ø³Ø¨Ø¨ Ø§Ù„ØªÙ†Ø¨Ø¤")

st.divider()

# Charts
l, r = st.columns(2)
alerts_summary = pd.DataFrame({
    "Ø§Ù„Ø­Ø§Ù„Ø©": ["Overdue", "Forecast Late", "On Track"],
    "Ø§Ù„Ø¹Ø¯Ø¯": [
        int(alerts["is_overdue"].sum()),
        int(alerts["is_forecast_late"].sum()),
        int(max(len(alerts) - alerts["is_overdue"].sum(), 0)),
    ],
})
l.plotly_chart(px.bar(alerts_summary, x="Ø§Ù„Ø­Ø§Ù„Ø©", y="Ø§Ù„Ø¹Ø¯Ø¯", title="ØªÙ†Ø¨ÙŠÙ‡Ø§Øª Ø§Ù„ØªØ£Ø®ÙŠØ±", color="Ø§Ù„Ø­Ø§Ù„Ø©", color_discrete_sequence=palette), use_container_width=True)

if "ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„Ù…Ø´Ø±ÙˆØ¹" in alerts.columns:
    tmp = alerts.copy()
    tmp = tmp[tmp["ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„Ù…Ø´Ø±ÙˆØ¹"].notna() | tmp["forecast_end"].notna()].copy()
    if len(tmp) > 0:
        tmp["project_label"] = tmp["Ø¥Ø³Ù… Ø§Ù„Ù…Ø´Ù€Ù€Ù€Ø±ÙˆØ¹"] if "Ø¥Ø³Ù… Ø§Ù„Ù…Ø´Ù€Ù€Ù€Ø±ÙˆØ¹" in tmp.columns else tmp.index.astype(str)
        r.plotly_chart(px.scatter(tmp, x="ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„Ù…Ø´Ø±ÙˆØ¹", y="forecast_end", hover_name="project_label", title="Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù…Ø®Ø·Ø· vs Ø§Ù„ØªÙ†Ø¨Ø¤ (Forecast)"), use_container_width=True)
    else:
        r.info("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ§ÙÙŠØ© Ù„Ø¹Ø±Ø¶ Ø§Ù„ØªÙ†Ø¨Ø¤.")
else:
    r.info("Ø¹Ù…ÙˆØ¯ 'ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„Ù…Ø´Ø±ÙˆØ¹' ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ Ù„Ø¹Ø±Ø¶ Ø§Ù„ØªÙ†Ø¨Ø¤.")

st.divider()

# Map (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
if show_map:
    st.subheader("ğŸ—ºï¸ Ø§Ù„Ø®Ø±ÙŠØ·Ø© (ØªØªØºÙŠØ± Ø­Ø³Ø¨ Ø§Ù„ÙÙ„Ø§ØªØ±)")
    geo = ensure_latlon(filtered).dropna(subset=[lat_col, lon_col]).copy()
    if len(geo) == 0:
        st.info("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¥Ø­Ø¯Ø§Ø«ÙŠØ§Øª. Ø£Ø¶ÙŠÙÙŠ lat/lon Ø£Ùˆ Ø±Ø§Ø¨Ø· Ù…ÙˆÙ‚Ø¹ ÙÙŠ Excel.")
    else:
        st.map(pd.DataFrame({"lat": geo[lat_col].astype(float), "lon": geo[lon_col].astype(float)}), zoom=10)

st.divider()

# Ø¬Ø¯ÙˆÙ„
st.subheader("ğŸ“‹ Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ù…Ø´Ø§Ø±ÙŠØ¹ (Ø¨Ø¹Ø¯ Ø§Ù„ÙÙ„ØªØ±Ø©)")
st.dataframe(filtered, use_container_width=True)
