import os
import re
from datetime import date

import pandas as pd
import streamlit as st
import plotly.express as px

from utils.layout import render_header
from utils.settings import load_settings

# --------------------------------------------------
# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø©
# --------------------------------------------------
st.set_page_config(page_title="Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©", page_icon="ğŸ ", layout="wide")
import streamlit as st

st.set_page_config(
    page_title="Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©",
    page_icon="ğŸ ",
    layout="wide"
)

# ==================================================
# ğŸ¨ ØªØ®ØµÙŠØµ Ø§Ù„Ø³Ø§ÙŠØ¯Ø¨Ø§Ø± (Ø¥Ø²Ø§Ù„Ø© App + ØªÙˆØ³ÙŠØ· Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ†)
# ==================================================
st.markdown("""
<style>
/* 1ï¸âƒ£ Ø­Ø°Ù ÙƒÙ„Ù…Ø© App (Ø¹Ù†ÙˆØ§Ù† Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„ØµÙØ­Ø§Øª) */
div[data-testid="stSidebarNav"] > div:first-child {
    display: none !important;
}

/* 2ï¸âƒ£ ØªÙˆØ³ÙŠØ· Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ø³Ø§ÙŠØ¯Ø¨Ø§Ø± Ø§Ù„Ù…Ø®ØµØµ */
section[data-testid="stSidebar"] h2 {
    text-align: center !important;
    width: 100%;
}

/* 3ï¸âƒ£ ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù…Ø³Ø§ÙØ§Øª */
section[data-testid="stSidebar"] {
    padding-top: 1rem;
}
</style>
""", unsafe_allow_html=True)

# ==================================================
# ğŸ  Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ† Ø§Ù„Ù„ÙŠ ØªØ¨ØºÙŠÙ†Ù‡Ø§ ÙØ¹Ù„ÙŠÙ‹Ø§
# ==================================================
st.sidebar.markdown(
    "<h2>ğŸ  Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©</h2>",
    unsafe_allow_html=True
)

st.sidebar.markdown(
    "<h3 style='text-align:center; margin-top:0.5rem;'>ğŸ“Š Ù„ÙˆØ­Ø© Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª</h3>",
    unsafe_allow_html=True
)

# âœ… Ø¥Ø®ÙØ§Ø¡ ÙƒÙ„Ù…Ø© App (Ø¹Ù†ÙˆØ§Ù† Ø§Ù„ØªÙ†Ù‚Ù„ Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ ÙÙŠ Ø§Ù„Ø³Ø§ÙŠØ¯Ø¨Ø§Ø±)
st.markdown(
    """
    <style>
    /* Hide the default "App" label in sidebar navigation */
    div[data-testid="stSidebarNav"] > div:first-child {
        display: none !important;
    }
    </style>
    """,
    unsafe_allow_html=True,
)

# âœ… Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ù„ÙŠ ØªØ¨ÙŠÙ†Ù‡ Ø¨Ø¯Ù„ App
st.sidebar.title("ğŸ  Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©")
st.sidebar.caption("ğŸ“Š Ù„ÙˆØ­Ø© Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª")

# Ù‡ÙŠØ¯Ø± Ø§Ù„Ù…ÙˆÙ‚Ø¹ (Ø§Ù„Ù„ÙˆÙ‚Ùˆ + Ø§Ù„Ø¹Ù†ÙˆØ§Ù† + Ø§Ù„Ù„ØºØ©)
render_header(title_key_base="dashboard_title", page_title_fallback="ğŸ“Š Ù„ÙˆØ­Ø© Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª")

# --------------------------------------------------
# Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
# --------------------------------------------------
settings = load_settings()
theme = settings.get("theme", {})
palette = theme.get("palette", ["#3B82F6", "#22C55E", "#F59E0B", "#EF4444", "#A855F7"])

data_cfg = settings.get("data", {})
lat_col = data_cfg.get("lat_col", "lat")
lon_col = data_cfg.get("lon_col", "lon")
map_link_col = data_cfg.get("map_link_col", "Ø±Ø§Ø¨Ø· Ø§Ù„Ù…ÙˆÙ‚Ø¹")
show_map = bool(data_cfg.get("show_map", True))

# --------------------------------------------------
# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
# --------------------------------------------------
path = os.path.join("data", "latest.xlsx")
if not os.path.exists(path):
    st.warning("Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù…Ù„Ù Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø¹Ø¯. Ø§Ø°Ù‡Ø¨ÙŠ Ù„ØµÙØ­Ø© (Ø±ÙØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª) ÙˆØ§Ø±ÙØ¹Ù Ù…Ù„Ù Excel.")
    st.stop()

df = pd.read_excel(path, sheet_name=0)
df.columns = [str(c).strip() for c in df.columns]

# --------------------------------------------------
# Helpers
# --------------------------------------------------
def safe_unique(frame: pd.DataFrame, col: str):
    if col not in frame.columns:
        return []
    return sorted([x for x in frame[col].dropna().unique().tolist()])

def parse_latlon_from_link(link: str):
    """ÙŠØ¯Ø¹Ù… Ø±ÙˆØ§Ø¨Ø· Google Maps Ù…Ø«Ù„ .../@lat,lon Ø£Ùˆ ?q=lat,lon"""
    if not isinstance(link, str) or not link:
        return None, None

    m = re.search(r"@(-?\d+\.\d+),(-?\d+\.\d+)", link)
    if m:
        return float(m.group(1)), float(m.group(2))

    m = re.search(r"[?&]q=(-?\d+\.\d+),(-?\d+\.\d+)", link)
    if m:
        return float(m.group(1)), float(m.group(2))

    return None, None

def ensure_latlon(frame: pd.DataFrame) -> pd.DataFrame:
    out = frame.copy()

    if lat_col in out.columns and lon_col in out.columns:
        out[lat_col] = pd.to_numeric(out[lat_col], errors="coerce")
        out[lon_col] = pd.to_numeric(out[lon_col], errors="coerce")
        return out

    if map_link_col in out.columns:
        lats, lons = [], []
        for x in out[map_link_col].fillna("").astype(str).tolist():
            la, lo = parse_latlon_from_link(x)
            lats.append(la)
            lons.append(lo)
        out[lat_col] = pd.to_numeric(pd.Series(lats), errors="coerce")
        out[lon_col] = pd.to_numeric(pd.Series(lons), errors="coerce")
        return out

    out[lat_col] = pd.NA
    out[lon_col] = pd.NA
    return out

def _fmt_days(x):
    try:
        if pd.isna(x):
            return "â€”"
        return f"{int(round(float(x))):,} ÙŠÙˆÙ…"
    except Exception:
        return "â€”"

def _fmt_pct(x):
    try:
        if pd.isna(x):
            return "â€”"
        return f"{float(x):.1f}%"
    except Exception:
        return "â€”"

def show_dropdown(table_df: pd.DataFrame, title: str):
    if len(table_df) == 0:
        st.info("Ù„Ø§ ØªÙˆØ¬Ø¯ Ù†ØªØ§Ø¦Ø¬.")
        return

    name_col = "Ø¥Ø³Ù… Ø§Ù„Ù…Ø´Ù€Ù€Ù€Ø±ÙˆØ¹" if "Ø¥Ø³Ù… Ø§Ù„Ù…Ø´Ù€Ù€Ù€Ø±ÙˆØ¹" in table_df.columns else None

    with st.expander(title, expanded=True):
        if name_col:
            st.markdown("**Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…Ø´Ø§Ø±ÙŠØ¹:**")
            for n in table_df[name_col].dropna().astype(str).unique().tolist():
                st.write("â€¢", n)
        else:
            st.info("Ø¹Ù…ÙˆØ¯ Ø§Ø³Ù… Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯.")

        cols_show = [c for c in [
            "Ø±Ù‚Ù… Ø§Ù„Ø¹Ù‚Ø¯",
            "Ø¥Ø³Ù… Ø§Ù„Ù…Ø´Ù€Ù€Ù€Ø±ÙˆØ¹",
            "Ø§Ù„Ø¨Ù„Ø¯ÙŠØ©",
            "Ø§Ù„Ø¬Ù‡Ø©",
            "Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ø´Ø±ÙˆØ¹",
            "Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²",
            "ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„Ù…Ø´Ø±ÙˆØ¹",
            "forecast_end",
            "variance_days",
            "reason",
        ] if c in table_df.columns]

        sort_cols = [c for c in ["is_overdue", "is_forecast_late", "variance_days"] if c in table_df.columns]
        if sort_cols:
            table_df = table_df.sort_values(by=sort_cols, ascending=[False] * len(sort_cols))

        st.dataframe(table_df[cols_show], use_container_width=True)

# --------------------------------------------------
# Sidebar filters (Ø¨Ø¯ÙˆÙ† Ø¹Ù†ÙˆØ§Ù† "Ø§Ù„ÙÙ„Ø§ØªØ±")
# --------------------------------------------------
status_opt = ["Ø§Ù„ÙƒÙ„"] + safe_unique(df, "Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ø´Ø±ÙˆØ¹")
mun_opt = ["Ø§Ù„ÙƒÙ„"] + safe_unique(df, "Ø§Ù„Ø¨Ù„Ø¯ÙŠØ©")
entity_opt = ["Ø§Ù„ÙƒÙ„"] + safe_unique(df, "Ø§Ù„Ø¬Ù‡Ø©")

status = st.sidebar.selectbox("Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ø´Ø±ÙˆØ¹", status_opt)
mun = st.sidebar.selectbox("Ø§Ù„Ø¨Ù„Ø¯ÙŠØ©", mun_opt)
entity = st.sidebar.selectbox("Ø§Ù„Ø¬Ù‡Ø©", entity_opt)

filtered = df.copy()
if status != "Ø§Ù„ÙƒÙ„" and "Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ø´Ø±ÙˆØ¹" in filtered.columns:
    filtered = filtered[filtered["Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ø´Ø±ÙˆØ¹"] == status]
if mun != "Ø§Ù„ÙƒÙ„" and "Ø§Ù„Ø¨Ù„Ø¯ÙŠØ©" in filtered.columns:
    filtered = filtered[filtered["Ø§Ù„Ø¨Ù„Ø¯ÙŠØ©"] == mun]
if entity != "Ø§Ù„ÙƒÙ„" and "Ø§Ù„Ø¬Ù‡Ø©" in filtered.columns:
    filtered = filtered[filtered["Ø§Ù„Ø¬Ù‡Ø©"] == entity]

# --------------------------------------------------
# KPIs
# --------------------------------------------------
k1, k2, k3, k4 = st.columns(4)
k1.metric("Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø´Ø§Ø±ÙŠØ¹", f"{len(filtered):,}")
k2.metric("Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ù‚ÙŠÙ…Ø© Ø§Ù„Ø¹Ù‚ÙˆØ¯", f"{filtered['Ù‚ÙŠÙ…Ø© Ø§Ù„Ø¹Ù‚Ø¯'].fillna(0).sum():,.0f}" if "Ù‚ÙŠÙ…Ø© Ø§Ù„Ø¹Ù‚Ø¯" in filtered.columns else "â€”")
k3.metric("Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…Ø³ØªØ®Ù„ØµØ§Øª", f"{filtered['Ù‚ÙŠÙ…Ø© Ø§Ù„Ù…Ø³ØªØ®Ù„ØµØ§Øª Ø§Ù„Ù…Ø¹ØªÙ…Ø¯Ù‡'].fillna(0).sum():,.0f}" if "Ù‚ÙŠÙ…Ø© Ø§Ù„Ù…Ø³ØªØ®Ù„ØµØ§Øª Ø§Ù„Ù…Ø¹ØªÙ…Ø¯Ù‡" in filtered.columns else "â€”")
k4.metric("Ù…ØªÙˆØ³Ø· Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²", f"{pd.to_numeric(filtered['Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²'], errors='coerce').fillna(0).mean():.1f}%" if "Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²" in filtered.columns else "â€”")

st.divider()

# --------------------------------------------------
# Alerts + Forecast
# --------------------------------------------------
alerts = filtered.copy()
today = pd.Timestamp(date.today())

if "ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„Ù…Ø´Ø±ÙˆØ¹" in alerts.columns:
    alerts["ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„Ù…Ø´Ø±ÙˆØ¹"] = pd.to_datetime(alerts["ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„Ù…Ø´Ø±ÙˆØ¹"], errors="coerce")
if "ØªØ§Ø±ÙŠØ® ØªØ³Ù„ÙŠÙ… Ø§Ù„Ù…ÙˆÙ‚Ø¹" in alerts.columns:
    alerts["ØªØ§Ø±ÙŠØ® ØªØ³Ù„ÙŠÙ… Ø§Ù„Ù…ÙˆÙ‚Ø¹"] = pd.to_datetime(alerts["ØªØ§Ø±ÙŠØ® ØªØ³Ù„ÙŠÙ… Ø§Ù„Ù…ÙˆÙ‚Ø¹"], errors="coerce")
if "Ø§Ù„Ù…Ø¯Ø© Ø§Ù„Ù…Ù†Ù‚Ø¶ÙŠØ© Ø¨Ø§Ù„Ø§ÙŠØ§Ù…" in alerts.columns:
    alerts["Ø§Ù„Ù…Ø¯Ø© Ø§Ù„Ù…Ù†Ù‚Ø¶ÙŠØ© Ø¨Ø§Ù„Ø§ÙŠØ§Ù…"] = pd.to_numeric(alerts["Ø§Ù„Ù…Ø¯Ø© Ø§Ù„Ù…Ù†Ù‚Ø¶ÙŠØ© Ø¨Ø§Ù„Ø§ÙŠØ§Ù…"], errors="coerce")
if "Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²" in alerts.columns:
    alerts["Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²"] = pd.to_numeric(alerts["Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²"], errors="coerce")

alerts["predicted_total_days"] = pd.Series([None] * len(alerts), dtype="float64")
alerts["forecast_end"] = pd.NaT

MAX_PREDICT_DAYS = 20000
MIN_PROGRESS = 0.5
MAX_PROGRESS = 100

can_forecast = (
    ("Ø§Ù„Ù…Ø¯Ø© Ø§Ù„Ù…Ù†Ù‚Ø¶ÙŠØ© Ø¨Ø§Ù„Ø§ÙŠØ§Ù…" in alerts.columns)
    and ("Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²" in alerts.columns)
    and ("ØªØ§Ø±ÙŠØ® ØªØ³Ù„ÙŠÙ… Ø§Ù„Ù…ÙˆÙ‚Ø¹" in alerts.columns)
)

if can_forecast:
    valid = (
        alerts["Ø§Ù„Ù…Ø¯Ø© Ø§Ù„Ù…Ù†Ù‚Ø¶ÙŠØ© Ø¨Ø§Ù„Ø§ÙŠØ§Ù…"].notna()
        & alerts["ØªØ§Ø±ÙŠØ® ØªØ³Ù„ÙŠÙ… Ø§Ù„Ù…ÙˆÙ‚Ø¹"].notna()
        & alerts["Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²"].notna()
        & (alerts["Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²"] >= MIN_PROGRESS)
        & (alerts["Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²"] <= MAX_PROGRESS)
        & (alerts["Ø§Ù„Ù…Ø¯Ø© Ø§Ù„Ù…Ù†Ù‚Ø¶ÙŠØ© Ø¨Ø§Ù„Ø§ÙŠØ§Ù…"] >= 0)
    )

    pred = alerts.loc[valid, "Ø§Ù„Ù…Ø¯Ø© Ø§Ù„Ù…Ù†Ù‚Ø¶ÙŠØ© Ø¨Ø§Ù„Ø§ÙŠØ§Ù…"] / (alerts.loc[valid, "Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²"] / 100.0)
    pred = pred.where((pred >= 0) & (pred <= MAX_PREDICT_DAYS), other=pd.NA)
    alerts.loc[valid, "predicted_total_days"] = pred

    valid2 = alerts["predicted_total_days"].notna()
    alerts.loc[valid2, "forecast_end"] = (
        alerts.loc[valid2, "ØªØ§Ø±ÙŠØ® ØªØ³Ù„ÙŠÙ… Ø§Ù„Ù…ÙˆÙ‚Ø¹"]
        + pd.to_timedelta(alerts.loc[valid2, "predicted_total_days"], unit="D", errors="coerce")
    )

alerts["is_overdue"] = False
if "ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„Ù…Ø´Ø±ÙˆØ¹" in alerts.columns:
    prog = alerts["Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²"] if "Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²" in alerts.columns else pd.Series([0] * len(alerts))
    alerts["is_overdue"] = (
        alerts["ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„Ù…Ø´Ø±ÙˆØ¹"].notna()
        & (today > alerts["ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„Ù…Ø´Ø±ÙˆØ¹"])
        & (prog.fillna(0) < 100)
    )

alerts["is_forecast_late"] = False
if "ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„Ù…Ø´Ø±ÙˆØ¹" in alerts.columns:
    alerts["is_forecast_late"] = (
        alerts["forecast_end"].notna()
        & alerts["ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„Ù…Ø´Ø±ÙˆØ¹"].notna()
        & (alerts["forecast_end"] > alerts["ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„Ù…Ø´Ø±ÙˆØ¹"])
    )

alerts["variance_days"] = pd.NA
if "ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„Ù…Ø´Ø±ÙˆØ¹" in alerts.columns:
    alerts["variance_days"] = (alerts["forecast_end"] - alerts["ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„Ù…Ø´Ø±ÙˆØ¹"]).dt.days

def build_reason(row):
    if bool(row.get("is_overdue", False)):
        planned = row.get("ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„Ù…Ø´Ø±ÙˆØ¹", pd.NaT)
        if pd.isna(planned):
            return "Ù…ØªØ£Ø®Ø± ÙØ¹Ù„ÙŠÙ‹Ø§: ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ø§Ù„Ù…Ø®Ø·Ø· ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯."
        return f"Ù…ØªØ£Ø®Ø± ÙØ¹Ù„ÙŠÙ‹Ø§: ØªØ¬Ø§ÙˆØ² Ø§Ù„Ù…Ø®Ø·Ø· Ø¨Ù€ {(today - planned).days} ÙŠÙˆÙ…."

    if bool(row.get("is_forecast_late", False)):
        progress = row.get("Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²", pd.NA)
        elapsed = row.get("Ø§Ù„Ù…Ø¯Ø© Ø§Ù„Ù…Ù†Ù‚Ø¶ÙŠØ© Ø¨Ø§Ù„Ø§ÙŠØ§Ù…", pd.NA)
        predicted = row.get("predicted_total_days", pd.NA)
        forecast_end = row.get("forecast_end", pd.NaT)
        planned_end = row.get("ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„Ù…Ø´Ø±ÙˆØ¹", pd.NaT)
        variance = row.get("variance_days", pd.NA)

        missing = []
        if pd.isna(progress): missing.append("Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²")
        if pd.isna(elapsed): missing.append("Ø§Ù„Ù…Ø¯Ø© Ø§Ù„Ù…Ù†Ù‚Ø¶ÙŠØ©")
        if pd.isna(predicted): missing.append("Ø£ÙŠØ§Ù… Ù…ØªÙˆÙ‚Ø¹Ø© Ø¥Ø¬Ù…Ø§Ù„Ù‹Ø§")
        if pd.isna(forecast_end): missing.append("ØªØ§Ø±ÙŠØ® Ø§Ù„ØªÙ†Ø¨Ø¤")
        if pd.isna(planned_end): missing.append("ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ø§Ù„Ù…Ø®Ø·Ø·")
        if missing:
            return "Ù…ØªÙˆÙ‚Ø¹ ÙŠØªØ£Ø®Ø±: Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± ÙƒØ§ÙÙŠØ© (" + "ØŒ ".join(missing) + ")."

        return (
            f"Ø§Ù„ØªÙ†Ø¨Ø¤: Ù…Ø¯Ø© {_fmt_days(elapsed)} Ù…Ø¹ Ø¥Ù†Ø¬Ø§Ø² {_fmt_pct(progress)} "
            f"â‡’ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ù…ØªÙˆÙ‚Ø¹ {_fmt_days(predicted)} "
            f"â‡’ ØªØ§Ø±ÙŠØ® Ø§Ù„ØªÙ†Ø¨Ø¤ {pd.to_datetime(forecast_end).date()} "
            f"Ø£Ø¨Ø¹Ø¯ Ù…Ù† Ø§Ù„Ù…Ø®Ø·Ø· Ø¨Ù€ {int(variance)} ÙŠÙˆÙ…."
        )

    return ""

alerts["reason"] = alerts.apply(build_reason, axis=1)

# --------------------------------------------------
# Toggle buttons (Ø¶ØºØ·Ø© ØªØ¸Ù‡Ø±/Ø¶ØºØ·Ø© ØªØ®ØªÙÙŠ)
# --------------------------------------------------
if "alerts_toggle" not in st.session_state:
    st.session_state.alerts_toggle = None  # None | overdue | forecast

overdue_count = int(alerts["is_overdue"].sum())
forecast_count = int(alerts["is_forecast_late"].sum())

col_over, col_fore = st.columns(2)

with col_over:
    if st.button(f"â›” Ù…ØªØ£Ø®Ø± ÙØ¹Ù„ÙŠÙ‹Ø§ â€¢ {overdue_count:,}", use_container_width=True, key="btn_overdue"):
        st.session_state.alerts_toggle = None if st.session_state.alerts_toggle == "overdue" else "overdue"
    if st.session_state.alerts_toggle == "overdue":
        show_dropdown(alerts[alerts["is_overdue"]].copy(), "ğŸ“Œ ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ù…ØªØ£Ø®Ø±Ø© ÙØ¹Ù„ÙŠÙ‹Ø§")

with col_fore:
    if st.button(f"âš ï¸ Ù…ØªÙˆÙ‚Ø¹ ÙŠØªØ£Ø®Ø± (Forecast) â€¢ {forecast_count:,}", use_container_width=True, key="btn_forecast"):
        st.session_state.alerts_toggle = None if st.session_state.alerts_toggle == "forecast" else "forecast"
    if st.session_state.alerts_toggle == "forecast":
        show_dropdown(alerts[alerts["is_forecast_late"]].copy(), "ğŸ“Œ ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹ ØªØ£Ø®Ø±Ù‡Ø§ + Ø³Ø¨Ø¨ Ø§Ù„ØªÙ†Ø¨Ø¤")

st.divider()

# --------------------------------------------------
# Charts
# --------------------------------------------------
l, r = st.columns(2)

alerts_summary = pd.DataFrame(
    {
        "Ø§Ù„Ø­Ø§Ù„Ø©": ["Overdue", "Forecast Late", "On Track"],
        "Ø§Ù„Ø¹Ø¯Ø¯": [
            int(alerts["is_overdue"].sum()),
            int(alerts["is_forecast_late"].sum()),
            int(max(len(alerts) - alerts["is_overdue"].sum(), 0)),
        ],
    }
)

fig_alerts = px.bar(
    alerts_summary,
    x="Ø§Ù„Ø­Ø§Ù„Ø©",
    y="Ø§Ù„Ø¹Ø¯Ø¯",
    title="ØªÙ†Ø¨ÙŠÙ‡Ø§Øª Ø§Ù„ØªØ£Ø®ÙŠØ±",
    color="Ø§Ù„Ø­Ø§Ù„Ø©",
    color_discrete_sequence=palette,
)
l.plotly_chart(fig_alerts, use_container_width=True)

if "ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„Ù…Ø´Ø±ÙˆØ¹" in alerts.columns:
    tmp = alerts.copy()
    tmp = tmp[tmp["ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„Ù…Ø´Ø±ÙˆØ¹"].notna() | tmp["forecast_end"].notna()].copy()
    if len(tmp) > 0:
        tmp["project_label"] = tmp["Ø¥Ø³Ù… Ø§Ù„Ù…Ø´Ù€Ù€Ù€Ø±ÙˆØ¹"] if "Ø¥Ø³Ù… Ø§Ù„Ù…Ø´Ù€Ù€Ù€Ø±ÙˆØ¹" in tmp.columns else tmp.index.astype(str)
        fig_fc = px.scatter(
            tmp,
            x="ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„Ù…Ø´Ø±ÙˆØ¹",
            y="forecast_end",
            hover_name="project_label",
            title="Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù…Ø®Ø·Ø· vs Ø§Ù„ØªÙ†Ø¨Ø¤ (Forecast)",
        )
        r.plotly_chart(fig_fc, use_container_width=True)
    else:
        r.info("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ§ÙÙŠØ© Ù„Ø¹Ø±Ø¶ Ø§Ù„ØªÙ†Ø¨Ø¤.")
else:
    r.info("Ø¹Ù…ÙˆØ¯ 'ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„Ù…Ø´Ø±ÙˆØ¹' ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ Ù„Ø¹Ø±Ø¶ Ø§Ù„ØªÙ†Ø¨Ø¤.")

st.divider()

# --------------------------------------------------
# Map (Ø§Ø®ØªÙŠØ§Ø±ÙŠ Ù…Ù† Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª)
# --------------------------------------------------
if show_map:
    st.subheader("ğŸ—ºï¸ Ø§Ù„Ø®Ø±ÙŠØ·Ø© (ØªØªØºÙŠØ± Ø­Ø³Ø¨ Ø§Ù„ÙÙ„Ø§ØªØ±)")

    geo = ensure_latlon(filtered)
    geo = geo.dropna(subset=[lat_col, lon_col]).copy()

    if len(geo) == 0:
        st.info("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¥Ø­Ø¯Ø§Ø«ÙŠØ§Øª. Ø£Ø¶ÙŠÙÙŠ ÙÙŠ Excel Ø£Ø¹Ù…Ø¯Ø© lat/lon Ø£Ùˆ Ø±Ø§Ø¨Ø· Google Maps ÙÙŠ Ø¹Ù…ÙˆØ¯ Ø±Ø§Ø¨Ø· Ø§Ù„Ù…ÙˆÙ‚Ø¹.")
    else:
        map_df = pd.DataFrame(
            {
                "lat": geo[lat_col].astype(float),
                "lon": geo[lon_col].astype(float),
            }
        )
        st.map(map_df, zoom=10)

    st.divider()

# --------------------------------------------------
# Regular charts
# --------------------------------------------------
g1, g2 = st.columns(2)

if "Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ø´Ø±ÙˆØ¹" in filtered.columns:
    fig1 = px.histogram(
        filtered,
        x="Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ø´Ø±ÙˆØ¹",
        title="ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù…Ø´Ø§Ø±ÙŠØ¹ Ø­Ø³Ø¨ Ø§Ù„Ø­Ø§Ù„Ø©",
        color_discrete_sequence=palette,
    )
    g1.plotly_chart(fig1, use_container_width=True)
else:
    g1.info("Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø¹Ù…ÙˆØ¯ 'Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ø´Ø±ÙˆØ¹'.")

if "Ø§Ù„Ø¨Ù„Ø¯ÙŠØ©" in filtered.columns:
    fig2 = px.histogram(
        filtered,
        x="Ø§Ù„Ø¨Ù„Ø¯ÙŠØ©",
        title="ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù…Ø´Ø§Ø±ÙŠØ¹ Ø­Ø³Ø¨ Ø§Ù„Ø¨Ù„Ø¯ÙŠØ©",
        color_discrete_sequence=palette,
    )
    g2.plotly_chart(fig2, use_container_width=True)
else:
    g2.info("Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø¹Ù…ÙˆØ¯ 'Ø§Ù„Ø¨Ù„Ø¯ÙŠØ©'.")

st.subheader("ğŸ“‹ Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ù…Ø´Ø§Ø±ÙŠØ¹ (Ø¨Ø¹Ø¯ Ø§Ù„ÙÙ„ØªØ±Ø©)")
st.dataframe(filtered, use_container_width=True)
