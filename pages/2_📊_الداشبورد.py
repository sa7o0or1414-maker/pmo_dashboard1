import os
import re
from datetime import date

import pandas as pd
import streamlit as st
import plotly.express as px

from utils.layout import render_header
from utils.settings import load_settings

# ---------- Page config ----------
st.set_page_config(page_title="Ø§Ù„Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯", layout="wide")
render_header(title_key_base="dashboard_title", page_title_fallback="ğŸ“Š Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ Ø§Ù„Ù…Ø´Ø§Ø±ÙŠØ¹")

# ---------- Settings ----------
settings = load_settings()
theme = settings.get("theme", {})
palette = theme.get("palette", ["#3B82F6", "#22C55E", "#F59E0B", "#EF4444", "#A855F7"])
data_cfg = settings.get("data", {})
lat_col = data_cfg.get("lat_col", "lat")
lon_col = data_cfg.get("lon_col", "lon")
map_link_col = data_cfg.get("map_link_col", "Ø±Ø§Ø¨Ø· Ø§Ù„Ù…ÙˆÙ‚Ø¹")

# ---------- Load data ----------
path = os.path.join("data", "latest.xlsx")
if not os.path.exists(path):
    st.warning("Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù…Ù„Ù Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø¹Ø¯. Ø§Ø°Ù‡Ø¨ÙŠ Ù„ØµÙØ­Ø© (Ø±ÙØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª) ÙˆØ§Ø±ÙØ¹Ù Ù…Ù„Ù Excel.")
    st.stop()

df = pd.read_excel(path, sheet_name=0)
df.columns = [str(c).strip() for c in df.columns]

# ---------- Helpers ----------
def safe_unique(frame: pd.DataFrame, col: str):
    if col not in frame.columns:
        return []
    return sorted([x for x in frame[col].dropna().unique().tolist()])

def parse_latlon_from_link(link: str):
    """ÙŠØ¯Ø¹Ù… Ø±ÙˆØ§Ø¨Ø· Google Maps Ù…Ø«Ù„ .../@lat,lon Ø£Ùˆ ?q=lat,lon"""
    if not isinstance(link, str) or not link:
        return None, None

    m = re.search(r"@(-?\d+\.\d+),(-?\d+\.\d+)", link)
    if m:
        return float(m.group(1)), float(m.group(2))

    m = re.search(r"[?&]q=(-?\d+\.\d+),(-?\d+\.\d+)", link)
    if m:
        return float(m.group(1)), float(m.group(2))

    return None, None

def ensure_latlon(frame: pd.DataFrame) -> pd.DataFrame:
    out = frame.copy()

    if lat_col in out.columns and lon_col in out.columns:
        out[lat_col] = pd.to_numeric(out[lat_col], errors="coerce")
        out[lon_col] = pd.to_numeric(out[lon_col], errors="coerce")
        return out

    if map_link_col in out.columns:
        lats, lons = [], []
        for x in out[map_link_col].fillna("").astype(str).tolist():
            la, lo = parse_latlon_from_link(x)
            lats.append(la)
            lons.append(lo)
        out[lat_col] = pd.to_numeric(pd.Series(lats), errors="coerce")
        out[lon_col] = pd.to_numeric(pd.Series(lons), errors="coerce")
        return out

    out[lat_col] = pd.NA
    out[lon_col] = pd.NA
    return out

def _fmt_days(x):
    try:
        if pd.isna(x):
            return "â€”"
        return f"{int(round(float(x))):,} ÙŠÙˆÙ…"
    except Exception:
        return "â€”"

def _fmt_pct(x):
    try:
        if pd.isna(x):
            return "â€”"
        return f"{float(x):.1f}%"
    except Exception:
        return "â€”"

def show_projects_dropdown(table_df: pd.DataFrame, title: str, show_reason: bool = True):
    """Ù…Ù†Ø³Ø¯Ù„Ø© ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§ ØªØ¹Ø±Ø¶: Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…Ø´Ø§Ø±ÙŠØ¹ + Ø¬Ø¯ÙˆÙ„ Ù…Ø¹ Ø£Ø³Ø¨Ø§Ø¨ (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)."""
    if len(table_df) == 0:
        st.info("Ù„Ø§ ØªÙˆØ¬Ø¯ Ù†ØªØ§Ø¦Ø¬.")
        return

    name_col = "Ø¥Ø³Ù… Ø§Ù„Ù…Ø´Ù€Ù€Ù€Ø±ÙˆØ¹" if "Ø¥Ø³Ù… Ø§Ù„Ù…Ø´Ù€Ù€Ù€Ø±ÙˆØ¹" in table_df.columns else None

    with st.expander(title, expanded=True):
        # Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…Ø´Ø§Ø±ÙŠØ¹
        if name_col:
            st.markdown("**Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…Ø´Ø§Ø±ÙŠØ¹:**")
            names = table_df[name_col].dropna().astype(str).unique().tolist()
            for n in names:
                st.write("â€¢", n)
        else:
            st.info("Ø¹Ù…ÙˆØ¯ Ø§Ø³Ù… Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯.")

        # Ø¬Ø¯ÙˆÙ„
        base_cols = [
            "Ø±Ù‚Ù… Ø§Ù„Ø¹Ù‚Ø¯",
            "Ø¥Ø³Ù… Ø§Ù„Ù…Ø´Ù€Ù€Ù€Ø±ÙˆØ¹",
            "Ø§Ù„Ø¨Ù„Ø¯ÙŠØ©",
            "Ø§Ù„Ø¬Ù‡Ø©",
            "Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ø´Ø±ÙˆØ¹",
            "Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²",
            "ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„Ù…Ø´Ø±ÙˆØ¹",
            "forecast_end",
            "variance_days",
        ]
        if show_reason:
            base_cols.insert(8, "reason")  # Ø³Ø¨Ø¨ Ø§Ù„ØªØ£Ø®Ø±/Ø§Ù„ØªÙ†Ø¨Ø¤

        cols_show = [c for c in base_cols if c in table_df.columns]

        # ØªØ±ØªÙŠØ¨: Ø§Ù„Ù…ØªØ£Ø®Ø± Ø£ÙˆÙ„Ù‹Ø§
        sort_cols = [c for c in ["is_overdue", "is_forecast_late", "variance_days"] if c in table_df.columns]
        if sort_cols:
            asc = [False, False, False][: len(sort_cols)]
            table_df = table_df.sort_values(by=sort_cols, ascending=asc)

        st.dataframe(table_df[cols_show], use_container_width=True)

# ---------- Sidebar filters (Ø¨Ø¯ÙˆÙ† ÙƒÙ„Ù…Ø© Ø§Ù„ÙÙ„Ø§ØªØ±) ----------
status_opt = ["Ø§Ù„ÙƒÙ„"] + safe_unique(df, "Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ø´Ø±ÙˆØ¹")
mun_opt = ["Ø§Ù„ÙƒÙ„"] + safe_unique(df, "Ø§Ù„Ø¨Ù„Ø¯ÙŠØ©")
entity_opt = ["Ø§Ù„ÙƒÙ„"] + safe_unique(df, "Ø§Ù„Ø¬Ù‡Ø©")

status = st.sidebar.selectbox("Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ø´Ø±ÙˆØ¹", status_opt)
mun = st.sidebar.selectbox("Ø§Ù„Ø¨Ù„Ø¯ÙŠØ©", mun_opt)
entity = st.sidebar.selectbox("Ø§Ù„Ø¬Ù‡Ø©", entity_opt)

filtered = df.copy()
if status != "Ø§Ù„ÙƒÙ„" and "Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ø´Ø±ÙˆØ¹" in filtered.columns:
    filtered = filtered[filtered["Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ø´Ø±ÙˆØ¹"] == status]
if mun != "Ø§Ù„ÙƒÙ„" and "Ø§Ù„Ø¨Ù„Ø¯ÙŠØ©" in filtered.columns:
    filtered = filtered[filtered["Ø§Ù„Ø¨Ù„Ø¯ÙŠØ©"] == mun]
if entity != "Ø§Ù„ÙƒÙ„" and "Ø§Ù„Ø¬Ù‡Ø©" in filtered.columns:
    filtered = filtered[filtered["Ø§Ù„Ø¬Ù‡Ø©"] == entity]

# ---------- KPIs ----------
k1, k2, k3, k4 = st.columns(4)
k1.metric("Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø´Ø§Ø±ÙŠØ¹", f"{len(filtered):,}")

if "Ù‚ÙŠÙ…Ø© Ø§Ù„Ø¹Ù‚Ø¯" in filtered.columns:
    k2.metric("Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ù‚ÙŠÙ…Ø© Ø§Ù„Ø¹Ù‚ÙˆØ¯", f"{filtered['Ù‚ÙŠÙ…Ø© Ø§Ù„Ø¹Ù‚Ø¯'].fillna(0).sum():,.0f}")
else:
    k2.metric("Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ù‚ÙŠÙ…Ø© Ø§Ù„Ø¹Ù‚ÙˆØ¯", "â€”")

if "Ù‚ÙŠÙ…Ø© Ø§Ù„Ù…Ø³ØªØ®Ù„ØµØ§Øª Ø§Ù„Ù…Ø¹ØªÙ…Ø¯Ù‡" in filtered.columns:
    k3.metric("Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…Ø³ØªØ®Ù„ØµØ§Øª", f"{filtered['Ù‚ÙŠÙ…Ø© Ø§Ù„Ù…Ø³ØªØ®Ù„ØµØ§Øª Ø§Ù„Ù…Ø¹ØªÙ…Ø¯Ù‡'].fillna(0).sum():,.0f}")
else:
    k3.metric("Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…Ø³ØªØ®Ù„ØµØ§Øª", "â€”")

if "Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²" in filtered.columns:
    k4.metric("Ù…ØªÙˆØ³Ø· Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²", f"{pd.to_numeric(filtered['Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²'], errors='coerce').fillna(0).mean():.1f}%")
else:
    k4.metric("Ù…ØªÙˆØ³Ø· Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²", "â€”")

st.divider()

# ---------- Alerts + Forecast ----------
alerts = filtered.copy()
today = pd.Timestamp(date.today())

# ØªØ¬Ù‡ÙŠØ² ØªÙˆØ§Ø±ÙŠØ®/Ø£Ø±Ù‚Ø§Ù…
if "ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„Ù…Ø´Ø±ÙˆØ¹" in alerts.columns:
    alerts["ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„Ù…Ø´Ø±ÙˆØ¹"] = pd.to_datetime(alerts["ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„Ù…Ø´Ø±ÙˆØ¹"], errors="coerce")

if "ØªØ§Ø±ÙŠØ® ØªØ³Ù„ÙŠÙ… Ø§Ù„Ù…ÙˆÙ‚Ø¹" in alerts.columns:
    alerts["ØªØ§Ø±ÙŠØ® ØªØ³Ù„ÙŠÙ… Ø§Ù„Ù…ÙˆÙ‚Ø¹"] = pd.to_datetime(alerts["ØªØ§Ø±ÙŠØ® ØªØ³Ù„ÙŠÙ… Ø§Ù„Ù…ÙˆÙ‚Ø¹"], errors="coerce")

if "Ø§Ù„Ù…Ø¯Ø© Ø§Ù„Ù…Ù†Ù‚Ø¶ÙŠØ© Ø¨Ø§Ù„Ø§ÙŠØ§Ù…" in alerts.columns:
    alerts["Ø§Ù„Ù…Ø¯Ø© Ø§Ù„Ù…Ù†Ù‚Ø¶ÙŠØ© Ø¨Ø§Ù„Ø§ÙŠØ§Ù…"] = pd.to_numeric(alerts["Ø§Ù„Ù…Ø¯Ø© Ø§Ù„Ù…Ù†Ù‚Ø¶ÙŠØ© Ø¨Ø§Ù„Ø§ÙŠØ§Ù…"], errors="coerce")

if "Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²" in alerts.columns:
    alerts["Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²"] = pd.to_numeric(alerts["Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²"], errors="coerce")

# ---------- Forecast (Ù…Ø­ØµÙ‘Ù†) ----------
alerts["predicted_total_days"] = pd.Series([None] * len(alerts), dtype="float64")
alerts["forecast_end"] = pd.NaT

MAX_PREDICT_DAYS = 20000
MIN_PROGRESS = 0.5
MAX_PROGRESS = 100

can_forecast = (
    ("Ø§Ù„Ù…Ø¯Ø© Ø§Ù„Ù…Ù†Ù‚Ø¶ÙŠØ© Ø¨Ø§Ù„Ø§ÙŠØ§Ù…" in alerts.columns) and
    ("Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²" in alerts.columns) and
    ("ØªØ§Ø±ÙŠØ® ØªØ³Ù„ÙŠÙ… Ø§Ù„Ù…ÙˆÙ‚Ø¹" in alerts.columns)
)

if can_forecast:
    valid = (
        alerts["Ø§Ù„Ù…Ø¯Ø© Ø§Ù„Ù…Ù†Ù‚Ø¶ÙŠØ© Ø¨Ø§Ù„Ø§ÙŠØ§Ù…"].notna() &
        alerts["ØªØ§Ø±ÙŠØ® ØªØ³Ù„ÙŠÙ… Ø§Ù„Ù…ÙˆÙ‚Ø¹"].notna() &
        alerts["Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²"].notna() &
        (alerts["Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²"] >= MIN_PROGRESS) &
        (alerts["Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²"] <= MAX_PROGRESS) &
        (alerts["Ø§Ù„Ù…Ø¯Ø© Ø§Ù„Ù…Ù†Ù‚Ø¶ÙŠØ© Ø¨Ø§Ù„Ø§ÙŠØ§Ù…"] >= 0)
    )

    pred = alerts.loc[valid, "Ø§Ù„Ù…Ø¯Ø© Ø§Ù„Ù…Ù†Ù‚Ø¶ÙŠØ© Ø¨Ø§Ù„Ø§ÙŠØ§Ù…"] / (alerts.loc[valid, "Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²"] / 100.0)
    pred = pred.where((pred >= 0) & (pred <= MAX_PREDICT_DAYS), other=pd.NA)
    alerts.loc[valid, "predicted_total_days"] = pred

    valid2 = alerts["predicted_total_days"].notna()
    alerts.loc[valid2, "forecast_end"] = (
        alerts.loc[valid2, "ØªØ§Ø±ÙŠØ® ØªØ³Ù„ÙŠÙ… Ø§Ù„Ù…ÙˆÙ‚Ø¹"] +
        pd.to_timedelta(alerts.loc[valid2, "predicted_total_days"], unit="D", errors="coerce")
    )

# Flags
alerts["is_overdue"] = False
if "ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„Ù…Ø´Ø±ÙˆØ¹" in alerts.columns:
    prog = alerts["Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²"] if "Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²" in alerts.columns else pd.Series([0] * len(alerts))
    alerts["is_overdue"] = (
        alerts["ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„Ù…Ø´Ø±ÙˆØ¹"].notna() &
        (today > alerts["ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„Ù…Ø´Ø±ÙˆØ¹"]) &
        (prog.fillna(0) < 100)
    )

alerts["is_forecast_late"] = False
if "ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„Ù…Ø´Ø±ÙˆØ¹" in alerts.columns:
    alerts["is_forecast_late"] = (
        alerts["forecast_end"].notna() &
        alerts["ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„Ù…Ø´Ø±ÙˆØ¹"].notna() &
        (alerts["forecast_end"] > alerts["ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„Ù…Ø´Ø±ÙˆØ¹"])
    )

# ---------- Reasons (Ø³Ø¨Ø¨ Ø§Ù„ØªØ£Ø®Ø±/Ø§Ù„ØªÙ†Ø¨Ø¤) ----------
alerts["variance_days"] = pd.NA  # Ø§Ù„ÙØ±Ù‚ Ø¨ÙŠÙ† forecast_end Ùˆ planned_end
if "ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„Ù…Ø´Ø±ÙˆØ¹" in alerts.columns:
    # variance_days = forecast_end - planned_end
    alerts["variance_days"] = (alerts["forecast_end"] - alerts["ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„Ù…Ø´Ø±ÙˆØ¹"]).dt.days

def build_reason(row):
    # Ù…ØªØ£Ø®Ø± ÙØ¹Ù„ÙŠÙ‹Ø§
    if bool(row.get("is_overdue", False)):
        planned = row.get("ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„Ù…Ø´Ø±ÙˆØ¹", pd.NaT)
        if pd.isna(planned):
            return "Ù…ØªØ£Ø®Ø± ÙØ¹Ù„ÙŠÙ‹Ø§: ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ø§Ù„Ù…Ø®Ø·Ø· ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯."
        days = (today - planned).days
        return f"Ù…ØªØ£Ø®Ø± ÙØ¹Ù„ÙŠÙ‹Ø§: ØªØ¬Ø§ÙˆØ² ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ø§Ù„Ù…Ø®Ø·Ø· Ø¨Ù€ {days} ÙŠÙˆÙ…."

    # Ù…ØªÙˆÙ‚Ø¹ ÙŠØªØ£Ø®Ø± (Forecast)
    if bool(row.get("is_forecast_late", False)):
        progress = row.get("Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²", pd.NA)
        elapsed = row.get("Ø§Ù„Ù…Ø¯Ø© Ø§Ù„Ù…Ù†Ù‚Ø¶ÙŠØ© Ø¨Ø§Ù„Ø§ÙŠØ§Ù…", pd.NA)
        predicted = row.get("predicted_total_days", pd.NA)
        forecast_end = row.get("forecast_end", pd.NaT)
        planned_end = row.get("ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„Ù…Ø´Ø±ÙˆØ¹", pd.NaT)
        variance = row.get("variance_days", pd.NA)

        # Ø¥Ø°Ø§ Ø¨ÙŠØ§Ù†Ø§Øª Ù†Ø§Ù‚ØµØ©
        missing = []
        if pd.isna(progress): missing.append("Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²")
        if pd.isna(elapsed): missing.append("Ø§Ù„Ù…Ø¯Ø© Ø§Ù„Ù…Ù†Ù‚Ø¶ÙŠØ©")
        if pd.isna(predicted): missing.append("Ø£ÙŠØ§Ù… Ù…ØªÙˆÙ‚Ø¹Ø© Ø¥Ø¬Ù…Ø§Ù„Ù‹Ø§")
        if pd.isna(forecast_end): missing.append("ØªØ§Ø±ÙŠØ® Ø§Ù„ØªÙ†Ø¨Ø¤")
        if pd.isna(planned_end): missing.append("ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ø§Ù„Ù…Ø®Ø·Ø·")

        if missing:
            return "Ù…ØªÙˆÙ‚Ø¹ ÙŠØªØ£Ø®Ø±: Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± ÙƒØ§ÙÙŠØ© (" + "ØŒ ".join(missing) + ")."

        # Ø±Ø³Ø§Ù„Ø© ØªÙØ³ÙŠØ± Ø§Ù„ØªÙ†Ø¨Ø¤
        return (
            f"Ø§Ù„ØªÙ†Ø¨Ø¤: Ø§Ù„Ù…Ø¯Ø© Ø§Ù„Ù…Ù†Ù‚Ø¶ÙŠØ© {_fmt_days(elapsed)} Ù…Ø¹ Ø¥Ù†Ø¬Ø§Ø² {_fmt_pct(progress)} "
            f"â‡’ Ø§Ù„Ø£ÙŠØ§Ù… Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø© Ø¥Ø¬Ù…Ø§Ù„Ù‹Ø§ {_fmt_days(predicted)} "
            f"â‡’ ØªØ§Ø±ÙŠØ® Ø§Ù„ØªÙ†Ø¨Ø¤ {pd.to_datetime(forecast_end).date()} "
            f"Ø£Ø¨Ø¹Ø¯ Ù…Ù† Ø§Ù„Ù…Ø®Ø·Ø· Ø¨Ù€ {int(variance)} ÙŠÙˆÙ…."
        )

    # Ù„Ø§ Ø´ÙŠØ¡
    return ""

alerts["reason"] = alerts.apply(build_reason, axis=1)

# ---------- Click-to-expand cards (Ù…Ù†Ø³Ø¯Ù„Ø© ØªØ­ØªÙ‡Ø§) ----------
if "alerts_view" not in st.session_state:
    st.session_state.alerts_view = None  # None | overdue | forecast | all

overdue_count = int(alerts["is_overdue"].sum())
forecast_count = int(alerts["is_forecast_late"].sum())

col_over, col_fore, col_all = st.columns([3, 3, 2])

with col_over:
    if st.button(f"â›” Ù…ØªØ£Ø®Ø± ÙØ¹Ù„ÙŠÙ‹Ø§ â€¢ {overdue_count:,}", use_container_width=True, key="btn_overdue"):
        st.session_state.alerts_view = "overdue"

    if st.session_state.alerts_view == "overdue":
        df_over = alerts[alerts["is_overdue"]].copy()
        # Ù„Ù„Ù…ØªØ£Ø®Ø± ÙØ¹Ù„ÙŠÙ‹Ø§: Ù†Ø¹Ø±Ø¶ Ø§Ù„Ø³Ø¨Ø¨ (Ø¹Ø¯Ø¯ Ø§Ù„Ø£ÙŠØ§Ù…)
        show_projects_dropdown(df_over, "ğŸ“Œ ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø±ÙŠØ¹ Ø§Ù„Ù…ØªØ£Ø®Ø±Ø© ÙØ¹Ù„ÙŠÙ‹Ø§", show_reason=True)

with col_fore:
    if st.button(f"âš ï¸ Ù…ØªÙˆÙ‚Ø¹ ÙŠØªØ£Ø®Ø± (Forecast) â€¢ {forecast_count:,}", use_container_width=True, key="btn_forecast"):
        st.session_state.alerts_view = "forecast"

    if st.session_state.alerts_view == "forecast":
        df_fc = alerts[alerts["is_forecast_late"]].copy()
        # Ù„Ù„ÙŠ Ù…ØªÙˆÙ‚Ø¹ ÙŠØªØ£Ø®Ø±: Ù†Ø¹Ø±Ø¶ Ø³Ø¨Ø¨ Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„ØªÙØµÙŠÙ„
        show_projects_dropdown(df_fc, "ğŸ“Œ ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø±ÙŠØ¹ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹ ØªØ£Ø®Ø±Ù‡Ø§ (Forecast) + Ø³Ø¨Ø¨ Ø§Ù„ØªÙ†Ø¨Ø¤", show_reason=True)

with col_all:
    if st.button("ğŸ” Ø¹Ø±Ø¶ Ø§Ù„ÙƒÙ„", use_container_width=True, key="btn_all"):
        st.session_state.alerts_view = "all"

    if st.session_state.alerts_view == "all":
        df_all = alerts[(alerts["is_overdue"]) | (alerts["is_forecast_late"])].copy()
        show_projects_dropdown(df_all, "ğŸ“Œ ÙƒÙ„ Ø§Ù„Ù…Ø´Ø§Ø±ÙŠØ¹ (Ù…ØªØ£Ø®Ø±Ø© + Ù…ØªÙˆÙ‚Ø¹ ØªØ£Ø®Ø±Ù‡Ø§) + Ø§Ù„Ø£Ø³Ø¨Ø§Ø¨", show_reason=True)

st.divider()

# ---------- Alerts charts ----------
l, r = st.columns(2)

alerts_summary = pd.DataFrame({
    "Ø§Ù„Ø­Ø§Ù„Ø©": ["Overdue", "Forecast Late", "On Track"],
    "Ø§Ù„Ø¹Ø¯Ø¯": [
        int(alerts["is_overdue"].sum()),
        int(alerts["is_forecast_late"].sum()),
        int(max(len(alerts) - alerts["is_overdue"].sum(), 0))
    ]
})

fig_alerts = px.bar(
    alerts_summary,
    x="Ø§Ù„Ø­Ø§Ù„Ø©",
    y="Ø§Ù„Ø¹Ø¯Ø¯",
    title="ØªÙ†Ø¨ÙŠÙ‡Ø§Øª Ø§Ù„ØªØ£Ø®ÙŠØ±",
    color="Ø§Ù„Ø­Ø§Ù„Ø©",
    color_discrete_sequence=palette
)
l.plotly_chart(fig_alerts, use_container_width=True)

if "ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„Ù…Ø´Ø±ÙˆØ¹" in alerts.columns:
    tmp = alerts.copy()
    tmp = tmp[tmp["ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„Ù…Ø´Ø±ÙˆØ¹"].notna() | tmp["forecast_end"].notna()].copy()
    if len(tmp) > 0:
        tmp["project_label"] = tmp["Ø¥Ø³Ù… Ø§Ù„Ù…Ø´Ù€Ù€Ù€Ø±ÙˆØ¹"] if "Ø¥Ø³Ù… Ø§Ù„Ù…Ø´Ù€Ù€Ù€Ø±ÙˆØ¹" in tmp.columns else tmp.index.astype(str)
        fig_fc = px.scatter(
            tmp,
            x="ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„Ù…Ø´Ø±ÙˆØ¹",
            y="forecast_end",
            hover_name="project_label",
            title="Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù…Ø®Ø·Ø· vs Ø§Ù„ØªÙ†Ø¨Ø¤ (Forecast)",
        )
        r.plotly_chart(fig_fc, use_container_width=True)
    else:
        r.info("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ§ÙÙŠØ© Ù„Ø¹Ø±Ø¶ Ø§Ù„ØªÙ†Ø¨Ø¤.")
else:
    r.info("Ø¹Ù…ÙˆØ¯ 'ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„Ù…Ø´Ø±ÙˆØ¹' ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ Ù„Ø¹Ø±Ø¶ Ø§Ù„ØªÙ†Ø¨Ø¤.")

st.divider()

# ---------- Map (changes with filters) ----------
st.subheader("ğŸ—ºï¸ Ø§Ù„Ø®Ø±ÙŠØ·Ø© (ØªØªØºÙŠØ± Ø­Ø³Ø¨ Ø§Ù„ÙÙ„Ø§ØªØ±)")

geo = ensure_latlon(filtered)
geo = geo.dropna(subset=[lat_col, lon_col]).copy()

if len(geo) == 0:
    st.info("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¥Ø­Ø¯Ø§Ø«ÙŠØ§Øª. Ø£Ø¶ÙŠÙÙŠ ÙÙŠ Excel Ø£Ø¹Ù…Ø¯Ø© lat/lon Ø£Ùˆ Ø±Ø§Ø¨Ø· Google Maps ÙÙŠ Ø¹Ù…ÙˆØ¯ Ø±Ø§Ø¨Ø· Ø§Ù„Ù…ÙˆÙ‚Ø¹.")
else:
    map_df = pd.DataFrame({
        "lat": geo[lat_col].astype(float),
        "lon": geo[lon_col].astype(float),
    })
    st.map(map_df, zoom=10)

st.divider()

# ---------- Regular charts ----------
g1, g2 = st.columns(2)

if "Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ø´Ø±ÙˆØ¹" in filtered.columns:
    fig1 = px.histogram(
        filtered,
        x="Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ø´Ø±ÙˆØ¹",
        title="ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù…Ø´Ø§Ø±ÙŠØ¹ Ø­Ø³Ø¨ Ø§Ù„Ø­Ø§Ù„Ø©",
        color_discrete_sequence=palette
    )
    g1.plotly_chart(fig1, use_container_width=True)
else:
    g1.info("Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø¹Ù…ÙˆØ¯ 'Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ø´Ø±ÙˆØ¹'.")

if "Ø§Ù„Ø¨Ù„Ø¯ÙŠØ©" in filtered.columns:
    fig2 = px.histogram(
        filtered,
        x="Ø§Ù„Ø¨Ù„Ø¯ÙŠØ©",
        title="ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù…Ø´Ø§Ø±ÙŠØ¹ Ø­Ø³Ø¨ Ø§Ù„Ø¨Ù„Ø¯ÙŠØ©",
        color_discrete_sequence=palette
    )
    g2.plotly_chart(fig2, use_container_width=True)
else:
    g2.info("Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø¹Ù…ÙˆØ¯ 'Ø§Ù„Ø¨Ù„Ø¯ÙŠØ©'.")

st.subheader("ğŸ“‹ Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ù…Ø´Ø§Ø±ÙŠØ¹ (Ø¨Ø¹Ø¯ Ø§Ù„ÙÙ„ØªØ±Ø©)")
st.dataframe(filtered, use_container_width=True)
