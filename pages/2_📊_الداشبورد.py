import os
import re
from datetime import date

import pandas as pd
import streamlit as st
import plotly.express as px

from utils.layout import render_header
from utils.settings import load_settings

# ---------- Page config ----------
st.set_page_config(page_title="Ø§Ù„Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯", layout="wide")
render_header(title_key_base="dashboard_title", page_title_fallback="ğŸ“Š Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ Ø§Ù„Ù…Ø´Ø§Ø±ÙŠØ¹")

# ---------- Settings ----------
settings = load_settings()
theme = settings.get("theme", {})
palette = theme.get("palette", ["#3B82F6", "#22C55E", "#F59E0B", "#EF4444", "#A855F7"])
data_cfg = settings.get("data", {})
lat_col = data_cfg.get("lat_col", "lat")
lon_col = data_cfg.get("lon_col", "lon")
map_link_col = data_cfg.get("map_link_col", "Ø±Ø§Ø¨Ø· Ø§Ù„Ù…ÙˆÙ‚Ø¹")

# ---------- Load data ----------
path = os.path.join("data", "latest.xlsx")
if not os.path.exists(path):
    st.warning("Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù…Ù„Ù Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø¹Ø¯. Ø§Ø°Ù‡Ø¨ÙŠ Ù„ØµÙØ­Ø© (Ø±ÙØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª) ÙˆØ§Ø±ÙØ¹Ù Ù…Ù„Ù Excel.")
    st.stop()

df = pd.read_excel(path, sheet_name=0)
df.columns = [str(c).strip() for c in df.columns]

# ---------- Helpers ----------
def safe_unique(frame: pd.DataFrame, col: str):
    if col not in frame.columns:
        return []
    return sorted([x for x in frame[col].dropna().unique().tolist()])

def parse_latlon_from_link(link: str):
    """
    ÙŠØ¯Ø¹Ù… Ø±ÙˆØ§Ø¨Ø· Google Maps Ù…Ø«Ù„:
    - .../@24.7136,46.6753,15z
    - ...?q=24.7136,46.6753
    """
    if not isinstance(link, str) or not link:
        return None, None

    m = re.search(r"@(-?\d+\.\d+),(-?\d+\.\d+)", link)
    if m:
        return float(m.group(1)), float(m.group(2))

    m = re.search(r"[?&]q=(-?\d+\.\d+),(-?\d+\.\d+)", link)
    if m:
        return float(m.group(1)), float(m.group(2))

    return None, None

def ensure_latlon(frame: pd.DataFrame) -> pd.DataFrame:
    out = frame.copy()

    if lat_col in out.columns and lon_col in out.columns:
        out[lat_col] = pd.to_numeric(out[lat_col], errors="coerce")
        out[lon_col] = pd.to_numeric(out[lon_col], errors="coerce")
        return out

    if map_link_col in out.columns:
        lats, lons = [], []
        for x in out[map_link_col].fillna("").astype(str).tolist():
            la, lo = parse_latlon_from_link(x)
            lats.append(la)
            lons.append(lo)
        out[lat_col] = pd.to_numeric(pd.Series(lats), errors="coerce")
        out[lon_col] = pd.to_numeric(pd.Series(lons), errors="coerce")
        return out

    out[lat_col] = pd.NA
    out[lon_col] = pd.NA
    return out

# ---------- Sidebar filters (Ø¨Ø¯ÙˆÙ† Ø¹Ù†ÙˆØ§Ù† "Ø§Ù„ÙÙ„Ø§ØªØ±") ----------
status_opt = ["Ø§Ù„ÙƒÙ„"] + safe_unique(df, "Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ø´Ø±ÙˆØ¹")
mun_opt = ["Ø§Ù„ÙƒÙ„"] + safe_unique(df, "Ø§Ù„Ø¨Ù„Ø¯ÙŠØ©")
entity_opt = ["Ø§Ù„ÙƒÙ„"] + safe_unique(df, "Ø§Ù„Ø¬Ù‡Ø©")

status = st.sidebar.selectbox("Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ø´Ø±ÙˆØ¹", status_opt)
mun = st.sidebar.selectbox("Ø§Ù„Ø¨Ù„Ø¯ÙŠØ©", mun_opt)
entity = st.sidebar.selectbox("Ø§Ù„Ø¬Ù‡Ø©", entity_opt)

filtered = df.copy()
if status != "Ø§Ù„ÙƒÙ„" and "Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ø´Ø±ÙˆØ¹" in filtered.columns:
    filtered = filtered[filtered["Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ø´Ø±ÙˆØ¹"] == status]
if mun != "Ø§Ù„ÙƒÙ„" and "Ø§Ù„Ø¨Ù„Ø¯ÙŠØ©" in filtered.columns:
    filtered = filtered[filtered["Ø§Ù„Ø¨Ù„Ø¯ÙŠØ©"] == mun]
if entity != "Ø§Ù„ÙƒÙ„" and "Ø§Ù„Ø¬Ù‡Ø©" in filtered.columns:
    filtered = filtered[filtered["Ø§Ù„Ø¬Ù‡Ø©"] == entity]

# ---------- KPIs ----------
k1, k2, k3, k4 = st.columns(4)
k1.metric("Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø´Ø§Ø±ÙŠØ¹", f"{len(filtered):,}")

if "Ù‚ÙŠÙ…Ø© Ø§Ù„Ø¹Ù‚Ø¯" in filtered.columns:
    k2.metric("Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ù‚ÙŠÙ…Ø© Ø§Ù„Ø¹Ù‚ÙˆØ¯", f"{filtered['Ù‚ÙŠÙ…Ø© Ø§Ù„Ø¹Ù‚Ø¯'].fillna(0).sum():,.0f}")
else:
    k2.metric("Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ù‚ÙŠÙ…Ø© Ø§Ù„Ø¹Ù‚ÙˆØ¯", "â€”")

if "Ù‚ÙŠÙ…Ø© Ø§Ù„Ù…Ø³ØªØ®Ù„ØµØ§Øª Ø§Ù„Ù…Ø¹ØªÙ…Ø¯Ù‡" in filtered.columns:
    k3.metric("Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…Ø³ØªØ®Ù„ØµØ§Øª", f"{filtered['Ù‚ÙŠÙ…Ø© Ø§Ù„Ù…Ø³ØªØ®Ù„ØµØ§Øª Ø§Ù„Ù…Ø¹ØªÙ…Ø¯Ù‡'].fillna(0).sum():,.0f}")
else:
    k3.metric("Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…Ø³ØªØ®Ù„ØµØ§Øª", "â€”")

if "Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²" in filtered.columns:
    k4.metric("Ù…ØªÙˆØ³Ø· Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²", f"{pd.to_numeric(filtered['Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²'], errors='coerce').fillna(0).mean():.1f}%")
else:
    k4.metric("Ù…ØªÙˆØ³Ø· Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²", "â€”")

st.divider()

# ---------- Alerts + Forecast ----------
alerts = filtered.copy()
today = pd.Timestamp(date.today())

# ØªØ¬Ù‡ÙŠØ² ØªÙˆØ§Ø±ÙŠØ®/Ø£Ø±Ù‚Ø§Ù…
if "ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„Ù…Ø´Ø±ÙˆØ¹" in alerts.columns:
    alerts["ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„Ù…Ø´Ø±ÙˆØ¹"] = pd.to_datetime(alerts["ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„Ù…Ø´Ø±ÙˆØ¹"], errors="coerce")

if "ØªØ§Ø±ÙŠØ® ØªØ³Ù„ÙŠÙ… Ø§Ù„Ù…ÙˆÙ‚Ø¹" in alerts.columns:
    alerts["ØªØ§Ø±ÙŠØ® ØªØ³Ù„ÙŠÙ… Ø§Ù„Ù…ÙˆÙ‚Ø¹"] = pd.to_datetime(alerts["ØªØ§Ø±ÙŠØ® ØªØ³Ù„ÙŠÙ… Ø§Ù„Ù…ÙˆÙ‚Ø¹"], errors="coerce")

if "Ø§Ù„Ù…Ø¯Ø© Ø§Ù„Ù…Ù†Ù‚Ø¶ÙŠØ© Ø¨Ø§Ù„Ø§ÙŠØ§Ù…" in alerts.columns:
    alerts["Ø§Ù„Ù…Ø¯Ø© Ø§Ù„Ù…Ù†Ù‚Ø¶ÙŠØ© Ø¨Ø§Ù„Ø§ÙŠØ§Ù…"] = pd.to_numeric(alerts["Ø§Ù„Ù…Ø¯Ø© Ø§Ù„Ù…Ù†Ù‚Ø¶ÙŠØ© Ø¨Ø§Ù„Ø§ÙŠØ§Ù…"], errors="coerce")

if "Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²" in alerts.columns:
    alerts["Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²"] = pd.to_numeric(alerts["Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²"], errors="coerce")

# ---------- Forecast (Ù…Ø­ØµÙ‘Ù† Ø¶Ø¯ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø´Ø§Ø°Ø©) ----------
alerts["predicted_total_days"] = pd.Series([None] * len(alerts), dtype="float64")
alerts["forecast_end"] = pd.NaT

MAX_PREDICT_DAYS = 20000  # Ø­Ø¯ Ø£Ù…Ø§Ù†
MIN_PROGRESS = 0.5        # Ø£Ù‚Ù„ Ø¥Ù†Ø¬Ø§Ø² Ù„Ù„ØªÙ†Ø¨Ø¤
MAX_PROGRESS = 100

can_forecast = (
    ("Ø§Ù„Ù…Ø¯Ø© Ø§Ù„Ù…Ù†Ù‚Ø¶ÙŠØ© Ø¨Ø§Ù„Ø§ÙŠØ§Ù…" in alerts.columns) and
    ("Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²" in alerts.columns) and
    ("ØªØ§Ø±ÙŠØ® ØªØ³Ù„ÙŠÙ… Ø§Ù„Ù…ÙˆÙ‚Ø¹" in alerts.columns)
)

if can_forecast:
    valid = (
        alerts["Ø§Ù„Ù…Ø¯Ø© Ø§Ù„Ù…Ù†Ù‚Ø¶ÙŠØ© Ø¨Ø§Ù„Ø§ÙŠØ§Ù…"].notna() &
        alerts["ØªØ§Ø±ÙŠØ® ØªØ³Ù„ÙŠÙ… Ø§Ù„Ù…ÙˆÙ‚Ø¹"].notna() &
        alerts["Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²"].notna() &
        (alerts["Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²"] >= MIN_PROGRESS) &
        (alerts["Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²"] <= MAX_PROGRESS) &
        (alerts["Ø§Ù„Ù…Ø¯Ø© Ø§Ù„Ù…Ù†Ù‚Ø¶ÙŠØ© Ø¨Ø§Ù„Ø§ÙŠØ§Ù…"] >= 0)
    )

    pred = alerts.loc[valid, "Ø§Ù„Ù…Ø¯Ø© Ø§Ù„Ù…Ù†Ù‚Ø¶ÙŠØ© Ø¨Ø§Ù„Ø§ÙŠØ§Ù…"] / (alerts.loc[valid, "Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²"] / 100.0)
    pred = pred.where((pred >= 0) & (pred <= MAX_PREDICT_DAYS), other=pd.NA)

    alerts.loc[valid, "predicted_total_days"] = pred

    valid2 = alerts["predicted_total_days"].notna()
    alerts.loc[valid2, "forecast_end"] = (
        alerts.loc[valid2, "ØªØ§Ø±ÙŠØ® ØªØ³Ù„ÙŠÙ… Ø§Ù„Ù…ÙˆÙ‚Ø¹"] +
        pd.to_timedelta(alerts.loc[valid2, "predicted_total_days"], unit="D", errors="coerce")
    )

# Overdue flag
alerts["is_overdue"] = False
if "ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„Ù…Ø´Ø±ÙˆØ¹" in alerts.columns:
    prog = alerts["Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²"] if "Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²" in alerts.columns else pd.Series([0] * len(alerts))
    alerts["is_overdue"] = (
        alerts["ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„Ù…Ø´Ø±ÙˆØ¹"].notna() &
        (today > alerts["ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„Ù…Ø´Ø±ÙˆØ¹"]) &
        (prog.fillna(0) < 100)
    )

# Forecast late flag
alerts["is_forecast_late"] = False
if "ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„Ù…Ø´Ø±ÙˆØ¹" in alerts.columns:
    alerts["is_forecast_late"] = (
        alerts["forecast_end"].notna() &
        alerts["ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„Ù…Ø´Ø±ÙˆØ¹"].notna() &
        (alerts["forecast_end"] > alerts["ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„Ù…Ø´Ø±ÙˆØ¹"])
    )

# ---------- Clickable Cards (show projects by click) ----------
if "alerts_view" not in st.session_state:
    st.session_state.alerts_view = "all"  # all | overdue | forecast

overdue_count = int(alerts["is_overdue"].sum())
forecast_count = int(alerts["is_forecast_late"].sum())

b1, b2, b3, b4 = st.columns([3, 3, 2, 2])

with b1:
    if st.button(f"â›” Ù…ØªØ£Ø®Ø± ÙØ¹Ù„ÙŠÙ‹Ø§ â€¢ {overdue_count:,}", use_container_width=True, key="btn_overdue"):
        st.session_state.alerts_view = "overdue"

with b2:
    if st.button(f"âš ï¸ Ù…ØªÙˆÙ‚Ø¹ ÙŠØªØ£Ø®Ø± (Forecast) â€¢ {forecast_count:,}", use_container_width=True, key="btn_forecast"):
        st.session_state.alerts_view = "forecast"

with b3:
    if st.button("ğŸ” Ø¹Ø±Ø¶ Ø§Ù„ÙƒÙ„", use_container_width=True, key="btn_all"):
        st.session_state.alerts_view = "all"

with b4:
    # ÙƒØ±Øª Ø¥Ø¶Ø§ÙÙŠ (Ø§Ø®ØªÙŠØ§Ø±ÙŠ): Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡Ø§Øª
    total_alerts = int(((alerts["is_overdue"]) | (alerts["is_forecast_late"])).sum())
    st.metric("Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡Ø§Øª", f"{total_alerts:,}")

st.divider()

# ---------- Alerts charts ----------
l, r = st.columns(2)

alerts_summary = pd.DataFrame({
    "Ø§Ù„Ø­Ø§Ù„Ø©": ["Overdue", "Forecast Late", "On Track"],
    "Ø§Ù„Ø¹Ø¯Ø¯": [
        int(alerts["is_overdue"].sum()),
        int(alerts["is_forecast_late"].sum()),
        int(max(len(alerts) - alerts["is_overdue"].sum(), 0))
    ]
})

fig_alerts = px.bar(
    alerts_summary,
    x="Ø§Ù„Ø­Ø§Ù„Ø©",
    y="Ø§Ù„Ø¹Ø¯Ø¯",
    title="ØªÙ†Ø¨ÙŠÙ‡Ø§Øª Ø§Ù„ØªØ£Ø®ÙŠØ±",
    color="Ø§Ù„Ø­Ø§Ù„Ø©",
    color_discrete_sequence=palette
)
l.plotly_chart(fig_alerts, use_container_width=True)

if "ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„Ù…Ø´Ø±ÙˆØ¹" in alerts.columns:
    tmp = alerts.copy()
    tmp = tmp[tmp["ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„Ù…Ø´Ø±ÙˆØ¹"].notna() | tmp["forecast_end"].notna()].copy()
    if len(tmp) > 0:
        tmp["project_label"] = tmp["Ø¥Ø³Ù… Ø§Ù„Ù…Ø´Ù€Ù€Ù€Ø±ÙˆØ¹"] if "Ø¥Ø³Ù… Ø§Ù„Ù…Ø´Ù€Ù€Ù€Ø±ÙˆØ¹" in tmp.columns else tmp.index.astype(str)
        fig_fc = px.scatter(
            tmp,
            x="ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„Ù…Ø´Ø±ÙˆØ¹",
            y="forecast_end",
            hover_name="project_label",
            title="Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù…Ø®Ø·Ø· vs Ø§Ù„ØªÙ†Ø¨Ø¤ (Forecast)",
        )
        r.plotly_chart(fig_fc, use_container_width=True)
    else:
        r.info("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ§ÙÙŠØ© Ù„Ø¹Ø±Ø¶ Ø§Ù„ØªÙ†Ø¨Ø¤.")
else:
    r.info("Ø¹Ù…ÙˆØ¯ 'ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„Ù…Ø´Ø±ÙˆØ¹' ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ Ù„Ø¹Ø±Ø¶ Ø§Ù„ØªÙ†Ø¨Ø¤.")

st.divider()

# ---------- Projects list based on clicked card ----------
st.subheader("ğŸ“Œ Ø§Ù„Ù…Ø´Ø§Ø±ÙŠØ¹ Ø­Ø³Ø¨ Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„ÙƒØ±Øª")

view = st.session_state.alerts_view

if view == "overdue":
    table_df = alerts[alerts["is_overdue"]].copy()
    st.caption("Ø¹Ø±Ø¶: Ø§Ù„Ù…Ø´Ø§Ø±ÙŠØ¹ Ø§Ù„Ù…ØªØ£Ø®Ø±Ø© ÙØ¹Ù„ÙŠÙ‹Ø§")
elif view == "forecast":
    table_df = alerts[alerts["is_forecast_late"]].copy()
    st.caption("Ø¹Ø±Ø¶: Ø§Ù„Ù…Ø´Ø§Ø±ÙŠØ¹ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹ ØªØ£Ø®Ø±Ù‡Ø§ (Forecast)")
else:
    table_df = alerts[(alerts["is_overdue"]) | (alerts["is_forecast_late"])].copy()
    st.caption("Ø¹Ø±Ø¶: ÙƒÙ„ Ø§Ù„Ù…ØªØ£Ø®Ø±Ø© + Ø§Ù„Ù…ØªÙˆÙ‚Ø¹ ØªØ£Ø®Ø±Ù‡Ø§")

name_col = "Ø¥Ø³Ù… Ø§Ù„Ù…Ø´Ù€Ù€Ù€Ø±ÙˆØ¹" if "Ø¥Ø³Ù… Ø§Ù„Ù…Ø´Ù€Ù€Ù€Ø±ÙˆØ¹" in table_df.columns else None
if len(table_df) == 0:
    st.info("Ù„Ø§ ØªÙˆØ¬Ø¯ Ù†ØªØ§Ø¦Ø¬ Ø­Ø³Ø¨ Ø§Ù„Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø­Ø§Ù„ÙŠ.")
else:
    # Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…Ø´Ø§Ø±ÙŠØ¹ (Ù‚Ø§Ø¦Ù…Ø©)
    if name_col:
        with st.expander("ğŸ“ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…Ø´Ø§Ø±ÙŠØ¹", expanded=True):
            names = table_df[name_col].dropna().astype(str).unique().tolist()
            for n in names:
                st.write("â€¢", n)
    else:
        st.info("Ø¹Ù…ÙˆØ¯ Ø§Ø³Ù… Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ Ù„Ø¹Ø±Ø¶ Ø§Ù„Ø£Ø³Ù…Ø§Ø¡.")

    # Ø¬Ø¯ÙˆÙ„ Ø§Ù„ØªÙØ§ØµÙŠÙ„
    cols_show = [c for c in [
        "Ø±Ù‚Ù… Ø§Ù„Ø¹Ù‚Ø¯",
        "Ø¥Ø³Ù… Ø§Ù„Ù…Ø´Ù€Ù€Ù€Ø±ÙˆØ¹",
        "Ø§Ù„Ø¨Ù„Ø¯ÙŠØ©",
        "Ø§Ù„Ø¬Ù‡Ø©",
        "Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ø´Ø±ÙˆØ¹",
        "Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²",
        "ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„Ù…Ø´Ø±ÙˆØ¹",
        "forecast_end"
    ] if c in table_df.columns]

    # ØªØ±ØªÙŠØ¨: Ø§Ù„Ù…ØªØ£Ø®Ø± Ø£ÙˆÙ„Ø§Ù‹
    sort_cols = [c for c in ["is_overdue", "is_forecast_late"] if c in table_df.columns]
    if sort_cols:
        table_df = table_df.sort_values(by=sort_cols, ascending=False)

    st.dataframe(table_df[cols_show], use_container_width=True)

st.divider()

# ---------- Map (changes with filters) ----------
st.subheader("ğŸ—ºï¸ Ø§Ù„Ø®Ø±ÙŠØ·Ø© (ØªØªØºÙŠØ± Ø­Ø³Ø¨ Ø§Ù„ÙÙ„Ø§ØªØ±)")

geo = ensure_latlon(filtered)
geo = geo.dropna(subset=[lat_col, lon_col]).copy()

if len(geo) == 0:
    st.info("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¥Ø­Ø¯Ø§Ø«ÙŠØ§Øª. Ø£Ø¶ÙŠÙÙŠ ÙÙŠ Excel Ø£Ø¹Ù…Ø¯Ø© lat/lon Ø£Ùˆ Ø±Ø§Ø¨Ø· Google Maps ÙÙŠ Ø¹Ù…ÙˆØ¯ Ø±Ø§Ø¨Ø· Ø§Ù„Ù…ÙˆÙ‚Ø¹.")
else:
    map_df = pd.DataFrame({
        "lat": geo[lat_col].astype(float),
        "lon": geo[lon_col].astype(float),
    })
    st.map(map_df, zoom=10)

st.divider()

# ---------- Regular charts ----------
g1, g2 = st.columns(2)

if "Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ø´Ø±ÙˆØ¹" in filtered.columns:
    fig1 = px.histogram(
        filtered,
        x="Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ø´Ø±ÙˆØ¹",
        title="ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù…Ø´Ø§Ø±ÙŠØ¹ Ø­Ø³Ø¨ Ø§Ù„Ø­Ø§Ù„Ø©",
        color_discrete_sequence=palette
    )
    g1.plotly_chart(fig1, use_container_width=True)
else:
    g1.info("Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø¹Ù…ÙˆØ¯ 'Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ø´Ø±ÙˆØ¹'.")

if "Ø§Ù„Ø¨Ù„Ø¯ÙŠØ©" in filtered.columns:
    fig2 = px.histogram(
        filtered,
        x="Ø§Ù„Ø¨Ù„Ø¯ÙŠØ©",
        title="ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù…Ø´Ø§Ø±ÙŠØ¹ Ø­Ø³Ø¨ Ø§Ù„Ø¨Ù„Ø¯ÙŠØ©",
        color_discrete_sequence=palette
    )
    g2.plotly_chart(fig2, use_container_width=True)
else:
    g2.info("Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø¹Ù…ÙˆØ¯ 'Ø§Ù„Ø¨Ù„Ø¯ÙŠØ©'.")

st.subheader("ğŸ“‹ Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ù…Ø´Ø§Ø±ÙŠØ¹ (Ø¨Ø¹Ø¯ Ø§Ù„ÙÙ„ØªØ±Ø©)")
st.dataframe(filtered, use_container_width=True)
